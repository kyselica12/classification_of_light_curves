{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "def get_new_net(cfg):\n",
    "    seed = np.random.randint(1000000)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "\n",
    "    return net\n",
    "\n",
    "def load_net(cfg, seed, checkpoint=\"latest\"):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "    \n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "    net.load(checkpoint)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test train on synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all:  20%|██        | 1/5 [00:01<00:04,  1.20s/it]c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\data\\data_load.py:22: RuntimeWarning: divide by zero encountered in log10\n",
      "  arr = -2.5 * np.log10(arr)\n",
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "label: atlasv -> 1620 training examples, 180 testing examples\n",
      "label: cz3 -> 1173 training examples, 130 testing examples\n",
      "label: falcon9 -> 1152 training examples, 128 testing examples\n",
      "label: globalstar -> 955 training examples, 106 testing examples\n",
      "label: h2a -> 1289 training examples, 143 testing examples\n",
      "Training set: 50000\n",
      "Validation set: 50000\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(net, sampler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [01:54<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(100, print_on=False, save_interval=20, tensorboard_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 atlasv\n",
      "1 cz3\n",
      "2 falcon9\n",
      "3 globalstar\n",
      "4 h2a\n",
      "Train:\n",
      "\tLoss: 0.00023927600113650866\n",
      "\tAcc: 97.616\n",
      "Validation:\n",
      "\tLoss: 0.0004295219167308759\n",
      "\tAcc: 96.654\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  atlasv   cz3  falcon9  globalstar   h2a\n",
      "0      atlasv    9441   559        0           0     0\n",
      "1         cz3       1  9634      342          23     0\n",
      "2     falcon9       0    46     9919           6    29\n",
      "3  globalstar       0    48        0        9870    82\n",
      "4         h2a       0    82      110         345  9463\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              atlasv        cz3    falcon9  globalstar       h2a\n",
      "Precision  94.410000  96.340000  99.190000   98.700000  94.63000\n",
      "Recall     99.989409  92.911563  95.641693   96.349082  98.84061\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/6classes\"\n",
    "trainer.load_data_from_file(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_set.data = trainer.train_set.data[trainer.train_set.labels != 1]\n",
    "trainer.train_set.labels = trainer.train_set.labels[trainer.train_set.labels != 1]\n",
    "trainer.train_set.labels[trainer.train_set.labels != 0] = trainer.train_set.labels[trainer.train_set.labels != 0] - 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/Fall_2021_2: 100%|██████████| 495/495 [00:01<00:00, 433.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9134, 300)\n",
      "(20844, 300)\n",
      "(1907, 300)\n",
      "(27295, 300)\n",
      "(2478, 300)\n"
     ]
    }
   ],
   "source": [
    "from data.data_load import load_data\n",
    "from data.filters import filter_data\n",
    "\n",
    "real_labels = [\"falcon_9\",\n",
    "          \"atlas_5\",\n",
    "          \"h-2a\",\n",
    "          \"globalstar\",\n",
    "          \"cz-3\"\n",
    "]\n",
    "labled_data = load_data(PACKAGE_PATH + \"/resources/Fall_2021_2\", labels=real_labels, convert_to_mag=False)\n",
    "\n",
    "filtered_data = filter_data(labled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "for key in filtered_data:\n",
    "    new_data[key.replace(\"_\", \"\").replace(\"-\", \"\").replace(\"5\", \"v\")] = filtered_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['atlasv', 'cz3', 'falcon9', 'globalstar', 'h2a']),\n",
       " ['atlasv', 'cz3', 'falcon9', 'globalstar', 'h2a'],\n",
       " dict_keys(['atlas_5', 'cz-3', 'falcon_9', 'globalstar', 'h-2a']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.keys(), LABELS, filtered_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_set = train_set\n",
    "# trainer.val_set = val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on real data with 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"RTRT_v2_sampler\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "cfg.data_config.validation_split = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt: 100%|██████████| 5/5 [00:00<00:00, 35.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 17080 examples.\n",
      "Label: cz_3 39000 examples.\n",
      "Label: falcon_9 5655 examples.\n",
      "Label: globalstar 42172 examples.\n",
      "Label: h2a 5860 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.516  0.9578 1.516  ... 1.516  0.9578 3.813 ]\n",
      "[1.516  0.243  3.813  ... 0.9578 0.9578 3.813 ]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "trainer = Trainer(net)\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [01:21<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(101, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.0032061392752120027\n",
      "\tAcc: 84.816\n",
      "Validation:\n",
      "\tLoss: 0.015361303875833005\n",
      "\tAcc: 48.088\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5   h2a  globalstar\n",
      "0        cz_3  1514      1966      401   998         121\n",
      "1    falcon_9   970      2592      446   876         116\n",
      "2     atlas_5   594       520     2472   768         646\n",
      "3         h2a   774       998      546  2518         164\n",
      "4  globalstar   611       264      815   384        2926\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "               cz_3   falcon_9    atlas_5       h2a  globalstar\n",
      "Precision  30.28000  51.840000  49.440000  50.36000   58.520000\n",
      "Recall     33.92337  40.883281  52.820513  45.41847   73.647118\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on real using augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 898468 \n",
      "\n",
      "cuda:0\n",
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all:  20%|██        | 1/5 [00:01<00:04,  1.02s/it]c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\data\\data_load.py:22: RuntimeWarning: divide by zero encountered in log10\n",
      "  arr = -2.5 * np.log10(arr)\n",
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: atlasv -> 1620 training examples, 180 testing examples\n",
      "label: cz3 -> 1620 training examples, 180 testing examples\n",
      "label: falcon9 -> 1620 training examples, 180 testing examples\n",
      "label: globalstar -> 1620 training examples, 180 testing examples\n",
      "label: h2a -> 1620 training examples, 180 testing examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\nn\\dataset.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  d[d!=-1] = (d[d!=-1] - min_value[i]) / diff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000\n",
      "Validation set: 50000\n",
      "50000\n",
      "58111\n"
     ]
    }
   ],
   "source": [
    "net, seed = get_new_net()\n",
    "trainer = Trainer(net, sampler=False)\n",
    "DATA_PATH = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/6classes\"\n",
    "print(len(trainer.train_set))\n",
    "trainer.load_data_from_file(DATA_PATH)\n",
    "print(len(trainer.train_set))\n",
    "remove_titan_class(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55736\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.dataset import create_datasets, AugmentedBalancedDataset, NetDataset\n",
    "\n",
    "dataset_args = {\n",
    "    \"max_noise\": 0.05, \n",
    "    \"num_gaps\": 2, \"min_gap_len\": 5,\n",
    "    \"max_gap_len\": 10, \n",
    "    \"gap_prob\": 0.01, \n",
    "    \"use_original_data\": True, \n",
    "    \"min_num_examples\": 10000\n",
    "}\n",
    "\n",
    "# train_set, val_set = create_datasets(new_data, LABELS, validation_split=0.1, output_folder=None, \n",
    "#                                 dataset_class=NetDataset, aditional_dataset_args={})\n",
    "\n",
    "train_set = AugmentedBalancedDataset(trainer.train_set.data, trainer.train_set.labels, **dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train_set = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 301/301 [05:44<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 atlasv\n",
      "1 cz3\n",
      "2 falcon9\n",
      "3 globalstar\n",
      "4 h2a\n",
      "Train:\n",
      "\tLoss: 0.002063445328441889\n",
      "\tAcc: 90.4765322233386\n",
      "Validation:\n",
      "\tLoss: 0.0027077191074343283\n",
      "\tAcc: 88.4329563812601\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  atlasv  cz3  falcon9  globalstar   h2a\n",
      "0      atlasv    1990   16       39          35    39\n",
      "1         cz3     116   64        6           7     4\n",
      "2     falcon9     162    8      649          16    54\n",
      "3  globalstar      44    4        5         185    14\n",
      "4         h2a      61   10       47          29  2586\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              atlasv        cz3    falcon9  globalstar        h2a\n",
      "Precision  93.912223  32.487310  73.003375   73.412698  94.621295\n",
      "Recall     83.860093  62.745098  86.997319   68.014706  95.884316\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(301, print_on=False, save_interval=100, tensorboard_on=True)\n",
    "trainer.evaluate(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv1d(1, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): MaxPool1d(kernel_size=5, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (7): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=592, out_features=128, bias=True)\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "def get_new_net(cfg):\n",
    "    seed = np.random.randint(1000000)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"TSTS_obs_15_75_v1\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "augmentation_cfg = AugmentationConfig(\n",
    "    min_examples = 5000,\n",
    "    roll=True,\n",
    "    add_gaps=True,\n",
    "    add_noise=True,\n",
    "    max_noise=.03,\n",
    "    keep_original=False,\n",
    "    num_gaps = 2,\n",
    "    gap_prob = .2,\n",
    "    min_gap_len = 5,\n",
    "    max_gap_len = 15\n",
    ")\n",
    "cfg.data_config.augmentation = augmentation_cfg\n",
    "# cfg.data_config.filter = FilterConfig()\n",
    "# cfg.data_config.filter.n_bins = 30\n",
    "# cfg.data_config.filter.n_gaps = 2\n",
    "# cfg.data_config.filter.gap_size = 2\n",
    "# cfg.data_config.filter.rms_ratio = .0\n",
    "# cfg.data_config.filter.non_zero_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = net.load(checkpoint=8)\n",
    "# cfg.seed = seed\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# random.seed(seed)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(net, sampler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 557.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[2492. 2515.  126. 1743. 1761. 1611. 1065.  126. 2241.  274.  798.  887.\n",
      "  128. 1484. 3751.  925. 1092. 1826. 2966.  973. 2433.  913.  443. 1549.\n",
      " 1655.  126. 3599. 1624.  127. 2038.  872. 1917. 1586. 1702. 2182. 3527.\n",
      " 2288.  117. 1626. 1108.  654. 1279.  701. 1532.  494. 1549. 2484. 1022.\n",
      " 1606. 1355.  798. 2460. 1077.  122.  127. 2388. 1976. 1761. 1828. 1973.\n",
      " 1279. 2088.  817. 1681.  123.  808. 1590. 3253. 3757.  122. 1299.  768.\n",
      "  972.  554.  768.  141. 2785. 1735. 2531. 2633. 1954. 1399.  847.  910.\n",
      " 2286. 3599.  554.  554. 1253. 2222. 1167. 1550.  942. 2222. 1105. 3253.\n",
      "  654. 2484. 1270. 3631.  816. 1549. 2204. 1043.  123. 2288.  847.  764.\n",
      " 1962. 2515. 2112.  591. 2564.  203.  872. 1761. 1244. 2038.  190. 2100.\n",
      "  203.  349. 1681. 1613.  271. 1285.  910. 1164.  494. 1279.  710. 1108.\n",
      " 2038.  299. 2438. 2663. 1180. 1377.  122. 2288. 2038. 1249. 1463.  905.\n",
      " 1231. 2978. 2088.  740. 3820. 2809. 1152.  992. 2663. 3397. 3751. 1876.\n",
      " 3397. 1485. 1611.  124.  899.  127. 1077. 2492. 3788. 1097. 1012. 1820.\n",
      " 1976. 1167. 1954.  992.  899.  177. 2343. 1462. 2388. 2852. 3437. 2343.\n",
      " 1876. 2027. 1976. 1164. 2100. 1247. 1956. 2397.  203. 2251.  122. 1048.\n",
      " 3788. 1079.  200. 1815. 1312. 2189. 1008. 1202.  773. 3159. 2343. 1877.\n",
      " 1230. 3367.  306.  303.  117. 2288. 3064. 2038. 2982.  239.  772. 1928.\n",
      " 1159. 1152. 2088. 3754. 1012. 3820.  127. 1108. 1529.  122. 2360.  640.\n",
      "  127. 2359. 1079. 1167.  750. 1231. 1108. 2507. 2131. 1876. 1231.  121.\n",
      " 2758. 3631. 2198. 1913. 1377.  817.  190. 2288. 1917. 1701. 2564. 1877.\n",
      " 1042. 1911.  117. 2251. 1761. 1043. 3673. 1112. 1092.  764.  722. 3631.\n",
      " 1976. 2088. 1299. 3788. 2241.  640.  817. 1065.  126.  239.  913. 2112.\n",
      " 1973.  126. 1928. 3767.  972. 2170. 1016. 1250.  899. 2460. 3599. 2189.\n",
      " 2251. 1885. 2185.  965. 1761. 1816.  830. 1231. 2614. 1839. 1112. 2531.\n",
      "  177. 1230. 1976. 1315. 1079. 2151. 3202. 1655. 1550.  122.  126.  745.\n",
      "  125. 3064.  992.  768. 1785.  972. 3476. 2484. 2385. 2395. 1741. 2027.\n",
      " 1250. 1758.  750. 2457. 2286. 2189. 1026. 1606. 2158. 3159. 1696. 1312.\n",
      " 1820. 1702. 2088. 2454. 2433. 1973. 1876. 2360. 2131. 2288.  127.  135.\n",
      "  740.  591. 3673. 1876.  190. 2127. 2343. 2397.  972. 1159.  740. 1463.\n",
      " 1270. 1159.  120.  872. 1167. 1396. 1105. 3788.  160.  847. 1641. 2073.\n",
      "  126. 3754. 1484. 1611. 1917. 3751. 2344. 1484. 2560. 2111. 1797. 2982.\n",
      " 2038. 2852.  494. 2560. 1065. 2388. 1928. 1065. 2680.  772.  133. 2286.\n",
      " 1862. 1249.  942. 1159. 1917. 1633. 2027. 1613. 3317. 2200. 3711. 1876.\n",
      " 1355. 1917. 2438. 1108. 1108.  177. 1816. 2288. 1840.  740. 1396. 1043.\n",
      " 2462. 1212. 2852. 1550. 2251. 2460. 1550. 1816. 1315. 2073. 2101. 2454.\n",
      "  604.  144.  126. 1956.  847. 1972. 1112.  899. 1146.  127. 1167.  740.\n",
      " 1911. 1758.  190. 1281. 1250. 1244. 3317. 1876.  123. 1097.  203.  554.\n",
      " 1761. 1830. 1354. 1696.  973.  274. 2484.  942. 1885. 1299.  847.  772.\n",
      " 1270. 1012. 2608. 1202. 1458.  836. 1865. 1008.  839. 1355.  790. 3599.\n",
      " 1202.  973.  133. 1016.  847.  648. 1798.  117. 2091.  126. 2159. 2560.\n",
      "  184. 2292. 1681.  120. 2809. 1390. 1250.  394. 1911.  303. 3317. 2131.\n",
      " 1840. 2388.  127. 1696.  271. 2038. 1270. 1549. 1008. 3001. 1613. 1186.\n",
      "  795. 1250. 2078. 1202. 1285. 2388. 1225. 2809.  203. 2701. 1733.  817.\n",
      " 1529. 2005.  992. 1108.  160. 1743.  942. 1815. 1613. 1976.  740. 1520.\n",
      "  992. 1701.  996. 1743.  120. 1819.  604. 1741.  160. 1377. 1105. 1536.\n",
      "  349. 2564. 1164. 2343. 1016. 1377. 1164.  972. 1047.  160.  547.  942.\n",
      "  202. 1065. 1399. 1007.  913. 2388. 1761. 3713. 2921.  992. 1279.  490.\n",
      " 1354.  125. 2564.  396.]\n",
      "[ 868.  793.  153. ... 1815.  883.  469.]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "cfg.data_config.validation_split = 0.1\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 301/301 [04:02<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(301, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.000891152670759398\n",
      "\tAcc: 95.98\n",
      "Validation:\n",
      "\tLoss: 0.011142647005266251\n",
      "\tAcc: 77.892\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5   h2a  globalstar\n",
      "0        cz_3  3319       274       53  1354           0\n",
      "1    falcon_9  1583      2630       82   705           0\n",
      "2     atlas_5   283        39     4494   184           0\n",
      "3         h2a   602       168      198  4030           2\n",
      "4  globalstar     0         0        0     0        5000\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz_3   falcon_9    atlas_5        h2a  globalstar\n",
      "Precision  66.380000  52.600000  89.880000  80.600000  100.000000\n",
      "Recall     57.352687  84.538734  93.101305  64.243584   99.960016\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test real trained network on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"RTRT_v1_687129\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "augmentation_cfg = AugmentationConfig(\n",
    "    min_examples = 5000,\n",
    "    roll=True,\n",
    "    add_gaps=True,\n",
    "    add_noise=True,\n",
    "    max_noise=.03,\n",
    "    keep_original=False,\n",
    "    num_gaps = 2,\n",
    "    gap_prob = .2,\n",
    "    min_gap_len = 5,\n",
    "    max_gap_len = 15\n",
    ")\n",
    "cfg.data_config.augmentation = augmentation_cfg\n",
    "cfg.data_config.validation_split = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 626.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[ 923. 1587. 1733. ... 1900. 1164. 2225.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.900e+01 4.380e+02 2.660e+02 2.000e+00 3.000e+00 1.217e+03 4.910e+02\n",
      " 1.255e+03 1.064e+03 4.440e+02 3.900e+02 2.000e+01 1.440e+03 7.900e+01\n",
      " 6.100e+02 3.000e+01 1.940e+02 1.550e+02 1.000e+00 1.400e+02 1.100e+01\n",
      " 1.000e+00 1.196e+03 7.020e+02 3.000e+00 2.392e+03 1.340e+02 8.900e+02\n",
      " 1.200e+02 1.959e+03 1.560e+02 1.830e+02 2.230e+02 6.400e+01 5.500e+01\n",
      " 1.000e+00 1.737e+03 9.500e+01 2.323e+03 7.100e+01 1.000e+00 1.360e+03\n",
      " 1.504e+03 1.442e+03 2.016e+03 9.510e+02 2.740e+02 5.000e+00 2.610e+02\n",
      " 2.500e+01 3.847e+03 9.640e+02 1.900e+02 3.460e+02 2.210e+02 1.692e+03\n",
      " 1.752e+03 3.600e+01 2.000e+00 9.000e+01 1.700e+01 1.702e+03 9.900e+01\n",
      " 1.826e+03 1.000e+00 1.000e+00 7.220e+02 1.200e+01 6.000e+02 1.000e+00\n",
      " 5.990e+02 2.741e+03 1.550e+02 3.182e+03 1.045e+03 5.580e+02 2.367e+03\n",
      " 2.000e+00 8.090e+02 1.949e+03 1.000e+00 2.400e+01 1.239e+03 2.388e+03\n",
      " 1.443e+03 2.000e+00 1.115e+03 5.100e+01 9.900e+01 1.000e+00 7.340e+02\n",
      " 9.060e+02 3.740e+02 5.220e+02 1.752e+03 1.000e+00 3.530e+02 2.900e+01\n",
      " 2.180e+02 1.000e+01 1.659e+03 2.112e+03 1.461e+03 1.181e+03 1.020e+03\n",
      " 1.188e+03 3.820e+02 2.579e+03 1.510e+02 8.350e+02 8.700e+01 1.309e+03\n",
      " 1.682e+03 3.000e+01 1.913e+03 1.470e+02 1.000e+00 1.060e+02 2.000e+01\n",
      " 1.570e+02 1.689e+03 6.870e+02 6.100e+01 1.000e+00 1.356e+03 2.000e+00\n",
      " 1.210e+02 1.663e+03 2.000e+00 9.800e+01 2.378e+03 2.920e+02 2.144e+03\n",
      " 1.000e+00 1.242e+03 3.000e+00 2.390e+02 1.270e+02 1.800e+02 1.565e+03\n",
      " 3.250e+02 9.400e+01 2.350e+02 5.000e+00 1.530e+02 5.820e+02 7.700e+02\n",
      " 2.285e+03 5.280e+02 1.590e+02 4.440e+02 2.300e+01 4.900e+01 3.910e+02\n",
      " 1.000e+00 4.770e+02 1.000e+00 2.735e+03 1.860e+02 9.900e+01 6.000e+02\n",
      " 4.000e+00 4.200e+02 3.300e+01 1.043e+03 1.000e+00 1.039e+03 3.770e+02\n",
      " 2.090e+02 6.850e+02 6.110e+02 3.700e+02 7.800e+01 3.073e+03 4.470e+02\n",
      " 2.760e+02 3.110e+02 1.778e+03 1.000e+00 2.994e+03 1.800e+01 4.440e+02\n",
      " 2.669e+03 9.000e+01 1.279e+03 8.160e+02 5.000e+00 1.280e+02 1.167e+03\n",
      " 3.800e+01 1.149e+03 1.000e+00 2.500e+01 2.000e+00 2.480e+02 7.800e+01\n",
      " 2.300e+01 9.600e+01 1.120e+02 1.629e+03 2.870e+02 7.000e+01 8.830e+02\n",
      " 1.939e+03 8.400e+01 1.000e+00 1.770e+02 3.000e+00 8.900e+02 1.452e+03\n",
      " 2.078e+03 1.476e+03 3.470e+02 6.900e+02 9.110e+02 1.532e+03 1.154e+03\n",
      " 3.000e+00 1.300e+01 1.802e+03 1.600e+01 3.120e+02 1.000e+00 1.704e+03\n",
      " 9.060e+02 4.950e+02 3.064e+03 9.100e+01 1.800e+01 1.700e+01 3.200e+01\n",
      " 1.103e+03 4.200e+02 1.220e+02 1.000e+00 1.833e+03 3.260e+02 4.940e+02\n",
      " 1.045e+03 2.000e+00 1.000e+00 2.020e+02 8.530e+02 7.060e+02 3.020e+02\n",
      " 1.000e+00 1.000e+00 1.000e+00 4.400e+02 4.290e+02 1.000e+00 2.800e+01\n",
      " 5.000e+00 1.289e+03 6.400e+02 5.000e+00 1.300e+01 3.910e+02 8.740e+02\n",
      " 7.230e+02 3.584e+03 1.360e+03 1.470e+02 4.790e+02 2.680e+03 4.100e+01\n",
      " 7.440e+02 1.023e+03 8.440e+02 3.640e+02 7.680e+02 6.110e+02 1.080e+02\n",
      " 2.041e+03 1.000e+00 6.800e+01 1.000e+00 1.331e+03 4.460e+02 8.300e+02\n",
      " 2.534e+03 5.870e+02 1.159e+03 1.209e+03 1.050e+02 2.530e+02 1.000e+00\n",
      " 9.900e+01 1.629e+03 3.500e+01 8.700e+01 1.004e+03 1.503e+03 6.700e+01\n",
      " 1.230e+02 1.000e+00 4.000e+00 4.100e+01 4.560e+02 1.528e+03 3.870e+02\n",
      " 5.200e+01 6.430e+02 2.140e+03 1.294e+03 1.186e+03 2.679e+03 2.350e+03\n",
      " 1.000e+00 2.590e+02 2.173e+03 2.980e+02 2.235e+03 1.369e+03 3.136e+03\n",
      " 1.000e+00 1.384e+03 6.240e+02 6.300e+01 1.000e+00 9.500e+02 2.348e+03\n",
      " 2.741e+03 3.850e+02 3.590e+02 2.060e+02 1.700e+01 1.453e+03 6.910e+02\n",
      " 1.292e+03 1.600e+01 1.439e+03 6.210e+02 3.701e+03 2.040e+02 1.500e+03\n",
      " 5.430e+02 1.159e+03 1.300e+03 1.000e+00 1.255e+03 3.184e+03 1.042e+03\n",
      " 5.580e+02 6.500e+01 1.063e+03 3.064e+03 6.420e+02 2.910e+02 2.000e+00\n",
      " 2.504e+03 2.000e+00 1.869e+03 2.000e+00 1.240e+02 1.000e+00 3.000e+01\n",
      " 2.190e+02 2.000e+01 3.066e+03 1.000e+00 8.400e+01 1.400e+01 1.316e+03\n",
      " 1.000e+00 1.167e+03 4.470e+02 1.330e+02 2.000e+00 6.450e+02 2.353e+03\n",
      " 1.942e+03 2.039e+03 9.960e+02 1.734e+03 2.136e+03 1.210e+02 3.640e+02\n",
      " 1.452e+03 2.000e+00 2.800e+01 1.138e+03 5.880e+02 1.480e+02 1.106e+03\n",
      " 1.417e+03 6.200e+01 7.520e+02 9.820e+02 4.200e+02 1.839e+03 1.000e+00\n",
      " 1.896e+03 2.200e+03 2.958e+03 1.000e+00 7.700e+02 7.200e+01 1.606e+03\n",
      " 2.100e+02 2.289e+03 6.320e+02 6.730e+02 2.361e+03 1.513e+03 1.000e+00\n",
      " 2.058e+03 9.000e+01 2.000e+00 9.510e+02 1.000e+00 1.072e+03 1.130e+03\n",
      " 3.000e+00 1.000e+00 2.930e+02 4.510e+02 1.066e+03 1.170e+02 8.600e+01\n",
      " 5.690e+02 4.920e+02 4.550e+02 2.190e+02 2.040e+02 1.000e+00 1.628e+03\n",
      " 3.159e+03 4.000e+00 5.830e+02 3.000e+00 1.866e+03 1.278e+03 7.000e+01\n",
      " 2.128e+03 2.000e+00 1.683e+03 1.140e+02 1.510e+02 6.860e+02 9.390e+02\n",
      " 2.000e+00 1.701e+03 1.000e+00 3.470e+02 1.866e+03 1.600e+02 1.000e+00\n",
      " 1.983e+03 2.000e+00 1.867e+03 3.360e+02 6.600e+01 2.000e+00 2.000e+01\n",
      " 1.600e+01 1.493e+03 9.470e+02 1.752e+03 2.080e+02 6.900e+01 1.250e+02\n",
      " 1.782e+03 1.000e+00 2.198e+03 3.151e+03 2.000e+00 1.785e+03 7.380e+02\n",
      " 5.520e+02 3.390e+02 2.070e+03 1.000e+00 7.860e+02 3.680e+02 4.900e+02\n",
      " 4.900e+02 1.412e+03 1.500e+02 9.100e+02 9.580e+02 1.000e+00 5.310e+02\n",
      " 1.170e+02 1.289e+03 7.400e+02 1.000e+00 2.100e+01 1.074e+03 2.740e+02\n",
      " 1.000e+00 1.956e+03 1.924e+03 1.046e+03 2.397e+03 3.530e+02 1.000e+00\n",
      " 1.000e+00 1.070e+03 1.369e+03 1.810e+02 1.608e+03 1.285e+03 5.190e+02\n",
      " 1.953e+03 4.510e+02 6.840e+02 2.160e+02 1.570e+02 5.580e+02 1.049e+03\n",
      " 5.900e+01 4.000e+00 1.252e+03 9.480e+02 1.522e+03 1.000e+00 1.343e+03\n",
      " 3.000e+00 6.210e+02 9.100e+01 1.040e+03 1.290e+02 1.168e+03 5.740e+02\n",
      " 1.169e+03 2.540e+02 1.272e+03 2.351e+03 4.000e+00 6.000e+00 1.866e+03\n",
      " 2.525e+03 1.544e+03 1.514e+03 2.674e+03 7.550e+02 1.621e+03 1.890e+02\n",
      " 1.570e+02 2.433e+03 1.730e+02 2.585e+03 1.699e+03 9.600e+01 1.726e+03\n",
      " 4.290e+02 1.255e+03 2.164e+03 6.480e+02 2.978e+03 6.410e+02 1.000e+00\n",
      " 2.600e+03 3.980e+02 2.080e+02 8.360e+02 1.190e+02 1.480e+02 1.700e+01\n",
      " 2.200e+03 1.077e+03 2.090e+02 1.684e+03 5.550e+02 8.300e+02 1.000e+00\n",
      " 9.060e+02 1.085e+03 9.000e+01 1.013e+03 9.880e+02 5.260e+02 1.586e+03\n",
      " 5.580e+02 7.350e+02 1.514e+03 1.000e+00 1.558e+03 4.270e+02]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "net = Net(cfg.net_config)\n",
    "net.load(checkpoint=10)\n",
    "trainer = Trainer(net)\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.3388745119816138\n",
      "\tAcc: 24.068\n",
      "Validation:\n",
      "\tLoss: 0.1888031129606694\n",
      "\tAcc: 22.156\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5  h2a  globalstar\n",
      "0        cz_3  3898       302      375  421           4\n",
      "1    falcon_9  3486       388      659  440          27\n",
      "2     atlas_5  3842       253      382  522           1\n",
      "3         h2a  3553       340      497  599          11\n",
      "4  globalstar  3736       109      303  580         272\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              cz_3   falcon_9    atlas_5        h2a  globalstar\n",
      "Precision  77.9600   7.760000   7.640000  11.980000    5.440000\n",
      "Recall     21.0532  27.873563  17.238267  23.380172   86.349206\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADED BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "# cfg.data_config.regexes = [\".*cz-3_all.*\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"TRTR_5_12_2022\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "\n",
    "cfg.data_config.filter = FilterConfig()\n",
    "cfg.data_config.filter.n_bins = 30\n",
    "cfg.data_config.filter.n_gaps = 0\n",
    "cfg.data_config.filter.gap_size = 2\n",
    "cfg.data_config.filter.rms_ratio = .0\n",
    "cfg.data_config.filter.non_zero_ratio = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(net, sampler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt2: 100%|██████████| 5/5 [00:00<00:00, 176.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 2633 examples.\n",
      "Label: cz-3 9522 examples.\n",
      "Label: falcon_9 1953 examples.\n",
      "Label: globalstar 4152 examples.\n",
      "Label: h-2a 2187 examples.\n",
      "2633 0.1\n",
      "9522 0.1\n",
      "1953 0.1\n",
      "4152 0.1\n",
      "2187 0.1\n",
      "Training set: 18399\n",
      "Validation set: 2048\n"
     ]
    }
   ],
   "source": [
    "cfg.data_config.validation_split = 0.1\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18399, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.train_set), len(trainer.val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 201/201 [01:26<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(201, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRTR_5_12_2022_784712'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.006920501294527706\n",
      "\tAcc: 84.38502092505027\n",
      "Validation:\n",
      "\tLoss: 0.018372868872228165\n",
      "\tAcc: 68.603515625\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3   814        23       53    31          32\n",
      "1    falcon_9   117        52       15     4           8\n",
      "2     atlas_5   124         5       94    13          28\n",
      "3        h-2a    63         5       16   114          21\n",
      "4  globalstar    33         7       17    28         331\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision  85.414481  26.530612  35.606061  52.054795   79.567308\n",
      "Recall     70.721112  56.521739  48.205128  60.000000   78.809524\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 417.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[3181.  680.  866. ...  994. 2070. 1252.]\n",
      "[1.492e+03 1.388e+03 5.580e+02 1.543e+03 1.606e+03 5.300e+01 2.500e+01\n",
      " 1.100e+02 1.000e+00 3.200e+02 1.760e+03 1.800e+01 1.115e+03 7.220e+02\n",
      " 9.500e+01 2.000e+00 9.190e+02 1.000e+00 1.335e+03 2.982e+03 3.010e+02\n",
      " 1.324e+03 1.597e+03 1.000e+00 6.300e+01 5.300e+01 1.000e+00 8.960e+02\n",
      " 1.922e+03 1.000e+00 2.000e+00 1.152e+03 1.340e+02 8.500e+01 1.000e+00\n",
      " 7.260e+02 4.000e+00 3.400e+02 1.962e+03 8.390e+02 3.200e+01 3.000e+00\n",
      " 3.617e+03 1.779e+03 3.000e+00 4.800e+01 5.090e+02 1.000e+00 4.610e+02\n",
      " 1.000e+00 7.060e+02 1.322e+03 1.720e+02 3.230e+02 1.000e+00 1.417e+03\n",
      " 7.100e+01 1.121e+03 3.760e+02 7.100e+01 1.366e+03 3.000e+02 3.661e+03\n",
      " 2.220e+02 6.000e+00 2.058e+03 2.000e+00 4.140e+02 2.011e+03 1.300e+02\n",
      " 1.910e+02 3.930e+02 4.330e+02 1.720e+02 2.860e+02 1.220e+02 2.000e+00\n",
      " 5.910e+02 2.000e+01 9.660e+02 6.400e+01 1.316e+03 1.000e+00 1.285e+03\n",
      " 1.806e+03 6.250e+02 6.420e+02 7.820e+02 1.900e+02 1.223e+03 1.692e+03\n",
      " 3.110e+02 1.000e+00 1.836e+03 3.000e+00 1.410e+02 6.180e+02 5.370e+02\n",
      " 1.794e+03 5.000e+00 1.900e+01 3.000e+00 5.000e+00 5.100e+02 4.000e+00\n",
      " 5.410e+02 5.000e+00 1.647e+03 2.750e+02 8.100e+01 3.000e+00 6.900e+01\n",
      " 1.410e+02 1.000e+00 1.630e+02 2.190e+02 8.500e+02 9.000e+00 3.630e+02\n",
      " 1.127e+03 1.310e+02 2.860e+02 3.760e+02 1.000e+00 1.460e+03 1.780e+02\n",
      " 8.870e+02 1.000e+00 4.950e+02 1.680e+03 5.410e+02 1.435e+03 3.480e+02\n",
      " 1.298e+03 5.390e+02 6.590e+02 5.810e+02 2.000e+00 1.760e+03 1.000e+00\n",
      " 4.000e+01 9.690e+02 1.700e+01 2.570e+02 8.700e+01 1.319e+03 1.483e+03\n",
      " 4.100e+01 2.350e+02 3.600e+01 3.100e+01 1.617e+03 1.430e+02 2.258e+03\n",
      " 1.270e+02 2.108e+03 5.630e+02 8.230e+02 5.700e+02 2.700e+01 1.260e+02\n",
      " 2.131e+03 3.340e+02 2.098e+03 3.100e+01 9.300e+01 3.518e+03 1.366e+03\n",
      " 4.580e+02 2.460e+02 1.120e+03 9.060e+02 7.240e+02 2.360e+02 1.600e+01\n",
      " 4.860e+02 6.700e+01 5.640e+02 1.290e+02 9.820e+02 9.800e+01 1.000e+00\n",
      " 9.900e+01 1.200e+02 1.000e+00 1.521e+03 2.500e+01 9.970e+02 1.700e+02\n",
      " 1.629e+03 9.900e+02 3.960e+02 1.000e+00 1.890e+02 1.200e+03 3.570e+02\n",
      " 2.000e+00 1.753e+03 2.468e+03 4.480e+02 1.968e+03 1.020e+03 6.110e+02\n",
      " 9.140e+02 1.600e+01 2.000e+00 2.738e+03 5.120e+02 5.850e+02 3.940e+02\n",
      " 2.289e+03 1.500e+01 7.350e+02 2.002e+03 1.498e+03 1.003e+03 5.260e+02\n",
      " 2.630e+02 5.880e+02 3.500e+02 1.741e+03 3.890e+02 5.000e+00 1.108e+03\n",
      " 1.865e+03 1.000e+00 2.000e+00 1.180e+02 1.258e+03 1.380e+02 2.670e+03\n",
      " 1.010e+03 9.650e+02 5.760e+02 2.133e+03 2.148e+03 1.000e+00 1.316e+03\n",
      " 1.000e+01 1.000e+00 1.510e+02 6.530e+02 4.100e+01 6.440e+02 9.700e+01\n",
      " 2.000e+00 6.900e+01 1.084e+03 2.480e+02 2.060e+02 2.289e+03 2.292e+03\n",
      " 1.240e+02 1.000e+00 6.000e+01 9.200e+01 4.910e+02 2.200e+02 1.420e+02\n",
      " 7.300e+01 6.670e+02 6.330e+02 1.868e+03 2.060e+03 1.407e+03 1.000e+00\n",
      " 6.580e+02 4.000e+00 1.160e+02 2.273e+03 2.000e+00 1.000e+00 3.360e+02\n",
      " 1.227e+03 3.900e+01 1.240e+02 1.097e+03 1.000e+00 2.780e+02 1.000e+00\n",
      " 8.670e+02 1.080e+02 2.390e+02 6.400e+01 1.000e+00 8.000e+00 7.590e+02\n",
      " 1.166e+03 3.110e+02 2.300e+02 1.410e+02 2.811e+03 6.300e+01 9.730e+02\n",
      " 1.912e+03 1.710e+03 2.136e+03 5.160e+02 3.000e+00 3.380e+02 1.487e+03\n",
      " 1.108e+03 1.810e+02 1.000e+00 9.000e+00 1.095e+03 1.830e+02 2.479e+03\n",
      " 3.321e+03 1.150e+02 1.083e+03 9.400e+01 1.000e+00 1.600e+01 1.273e+03\n",
      " 1.110e+02 5.500e+02 6.270e+02 1.900e+01 4.000e+00 1.366e+03 2.292e+03\n",
      " 1.726e+03 4.950e+02 6.830e+02 1.943e+03 2.000e+02 3.920e+02 1.800e+01\n",
      " 1.000e+00 1.000e+00 3.090e+02 1.550e+02 1.658e+03 1.472e+03 1.637e+03\n",
      " 1.322e+03 1.000e+00 2.407e+03 1.658e+03 2.480e+02 4.090e+02 1.000e+00\n",
      " 2.789e+03 1.000e+00 1.640e+02 1.000e+00 3.530e+02 2.000e+00 2.918e+03\n",
      " 4.820e+02 1.138e+03 1.087e+03 2.060e+02 6.500e+01 2.700e+02 1.000e+00\n",
      " 5.440e+02 1.000e+00 3.710e+02 8.000e+00 7.720e+02 2.550e+02 7.700e+02\n",
      " 8.670e+02 1.000e+02 8.400e+01 1.554e+03 1.000e+00 1.748e+03 1.720e+02\n",
      " 8.290e+02 1.940e+02 1.166e+03 8.700e+01 8.440e+02 4.470e+02 1.438e+03\n",
      " 2.000e+00 1.000e+00 1.000e+00 8.450e+02 1.550e+02 6.200e+01 1.200e+01\n",
      " 1.022e+03 1.773e+03 6.360e+02 9.760e+02 7.000e+00 2.510e+02 3.100e+01\n",
      " 1.036e+03 1.700e+02 1.815e+03 9.190e+02 1.040e+02 4.850e+02 5.000e+00\n",
      " 4.510e+02 1.662e+03 9.040e+02 2.930e+02 7.900e+01 7.340e+02 1.000e+00\n",
      " 2.000e+00 1.219e+03 2.343e+03 1.722e+03 1.163e+03 1.865e+03 1.127e+03\n",
      " 2.300e+01 5.540e+02 2.700e+01 7.180e+02 1.500e+01 1.314e+03 8.420e+02\n",
      " 4.050e+02 6.540e+02 1.158e+03 3.890e+02 5.500e+02 1.000e+00 1.000e+00\n",
      " 2.107e+03 1.400e+01 5.820e+02 7.100e+01 2.510e+02 6.080e+02 2.360e+03\n",
      " 3.260e+02 2.470e+02 2.000e+00 4.280e+02 1.870e+02 1.413e+03 9.800e+01\n",
      " 8.740e+02 1.322e+03 3.000e+00 6.070e+02 1.980e+02 5.690e+02 7.950e+02\n",
      " 1.234e+03 1.800e+01 3.560e+02 2.230e+02 7.400e+01 1.621e+03 4.500e+02\n",
      " 3.200e+02 8.000e+01 5.990e+02 1.534e+03 1.563e+03 3.673e+03 3.672e+03\n",
      " 4.000e+00 8.140e+02 1.943e+03 1.000e+00 1.670e+03 9.670e+02 2.700e+01\n",
      " 1.510e+03 7.630e+02 5.510e+02 3.650e+02 8.420e+02 2.000e+00 2.090e+02\n",
      " 2.650e+02 4.550e+02 1.000e+00 1.556e+03 1.400e+01 3.124e+03 3.000e+00\n",
      " 9.800e+01 1.438e+03 1.000e+00 5.740e+02 2.550e+03 1.574e+03 6.000e+00\n",
      " 1.490e+02 8.600e+02 7.900e+01 1.080e+02 8.840e+02 1.860e+02 3.810e+02\n",
      " 1.120e+02 3.540e+02 6.090e+02 4.120e+02 1.163e+03 3.300e+01 1.000e+00\n",
      " 1.221e+03 1.367e+03 1.632e+03 2.000e+01 2.145e+03 4.760e+02 1.341e+03\n",
      " 7.250e+02 1.000e+00 2.826e+03 6.460e+02 1.000e+00 5.400e+02 1.600e+02\n",
      " 2.470e+02 1.000e+00 5.370e+02 1.133e+03 9.510e+02 7.900e+01 1.911e+03\n",
      " 1.940e+02 2.000e+00 1.000e+00 3.060e+02 3.300e+02 3.767e+03 2.360e+02\n",
      " 1.388e+03 1.600e+02 7.060e+02 3.500e+01 4.690e+02 1.000e+00 5.650e+02\n",
      " 3.650e+02 1.880e+02 1.659e+03 4.000e+00 1.281e+03 2.770e+02 7.900e+02\n",
      " 1.000e+00 4.200e+01 3.170e+02 1.586e+03 1.331e+03 3.200e+01 2.044e+03\n",
      " 2.204e+03 2.490e+03 1.000e+00 2.517e+03 6.700e+01 1.204e+03 3.000e+00\n",
      " 1.728e+03 1.702e+03 6.990e+02 1.000e+00 1.000e+00 2.330e+02 1.380e+02\n",
      " 2.740e+02 1.000e+02 5.690e+02 3.000e+00 2.306e+03 9.610e+02 3.390e+02\n",
      " 1.800e+01 1.000e+00 4.050e+02 1.254e+03 2.000e+01 1.760e+02]\n",
      "Training set: 580\n",
      "Validation set: 5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_synthetic_config = DataConfig()\n",
    "test_synthetic_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "test_synthetic_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "test_synthetic_config.convert_to_mag = False\n",
    "\n",
    "test_synthetic_config.validation_split = 0.9\n",
    "trainer.load_data(test_synthetic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.val_set.data.shape[0] / 5\n",
    "trainer.train_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.7063610124998069\n",
      "\tAcc: 16.896551724137932\n",
      "Validation:\n",
      "\tLoss: 0.47414291971787925\n",
      "\tAcc: 18.52490421455939\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5  h2a  globalstar\n",
      "0        cz_3   866         6      164    8           0\n",
      "1    falcon_9   800        12      188   40           4\n",
      "2     atlas_5   911        44       89    0           0\n",
      "3         h2a   637         2      405    0           0\n",
      "4  globalstar  1017        11       16    0           0\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz_3   falcon_9    atlas_5  h2a  globalstar\n",
      "Precision  82.950192   1.149425   8.524904  0.0         0.0\n",
      "Recall     20.467974  16.000000  10.324826  0.0         0.0\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(test_synthetic_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ-3B with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "OUTPUT_PATH = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3\"\n",
    "\n",
    "# number of  data in training set\n",
    "N = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "# cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "# cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3_all$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt_unbalanced_cz3: 100%|██████████| 5/5 [00:00<00:00, 626.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: cz-3 7522 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_load import load_data\n",
    "from src.data.filters import filter_data\n",
    "\n",
    "data = load_data(cfg.data_config.path, cfg.data_config.labels, cfg.data_config.regexes, cfg.data_config.convert_to_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"cz-3\"\n",
    "data = data[label]\n",
    "indices = list(range(len(data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_data = data[indices[:N]]\n",
    "test_data = data[indices[N:]]\n",
    "\n",
    "np.save(f\"{OUTPUT_PATH}/test_{label}.npy\", test_data)\n",
    "np.save(f\"{OUTPUT_PATH}/{label}.npy\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with unbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "# cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3$\", r\"^falcon.?9$\", r\"^atlas.?5$\", r\"^h.?2a$\", r\"^globalstar$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"Unbalanced_cz3\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/unbalanced\"\n",
    "\n",
    "cfg.data_config.filter = FilterConfig()\n",
    "cfg.data_config.filter.n_bins = 30\n",
    "cfg.data_config.filter.n_gaps = 2\n",
    "cfg.data_config.filter.gap_size = 2\n",
    "cfg.data_config.filter.rms_ratio = .0\n",
    "cfg.data_config.filter.non_zero_ratio = 0.8\n",
    "\n",
    "np.load(f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3/test_data/falcon_9.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt2: 100%|██████████| 5/5 [00:00<00:00, 156.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 2633 examples.\n",
      "Label: cz-3 9522 examples.\n",
      "Label: falcon_9 1953 examples.\n",
      "Label: globalstar 4152 examples.\n",
      "Label: h-2a 2187 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 16360\n",
      "Validation set: 4087\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)\n",
    "\n",
    "trainer = Trainer(net, sampler=False)\n",
    "cfg.data_config.validation_split = 0.2\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_data(f\"{OUTPUT_PATH}/data_set_unbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 201/201 [01:20<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(201, 128,tensorboard_on=True, save_interval=50, print_on=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6719639  0.1218349  0.49928673 ... 0.62184766 0.73019231 0.07195767]\n",
      "[0.55602716 0.67909424 0.62140954 ... 0.01081043 0.57581549 0.61943754]\n"
     ]
    }
   ],
   "source": [
    "test_config = DataConfig()\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3/test_data\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3$\", r\"^falcon.?9$\", r\"^atlas.?5$\", r\"^h.?2a$\", r\"^globalstar$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "\n",
    "trainer.load_data(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.0026340790050717097\n",
      "\tAcc: 94.66992665036675\n",
      "Validation:\n",
      "\tLoss: 0.01280817414325924\n",
      "\tAcc: 84.68314166870566\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3  1705        78       40    53          28\n",
      "1    falcon_9   113       250        8     9          10\n",
      "2     atlas_5   104        16      369    28           9\n",
      "3        h-2a    31         5        7   385           9\n",
      "4  globalstar    17         7       20    34         752\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision  89.548319  64.102564  70.152091  88.100686   90.602410\n",
      "Recall     86.548223  70.224719  83.108108  75.638507   93.069307\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cz_3_data = np.load(f\"{OUTPUT_PATH}/test_cz3.npy\")\n",
    "cz3_labels = np.zeros((len(cz_3_data),)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.val_set.data = np.concatenate([trainer.val_set.data, cz_3_data])\n",
    "trainer.val_set.labels = np.concatenate([trainer.val_set.labels, cz3_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.00033201762138303665\n",
      "\tAcc: 99.69915764139591\n",
      "Validation:\n",
      "\tLoss: 8.177975262498421\n",
      "\tAcc: 13.718370588902758\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3   181         5       12     6        7518\n",
      "1    falcon_9     7       182        1     0           5\n",
      "2     atlas_5    13         7      230     1          12\n",
      "3        h-2a     8         5        2   203           0\n",
      "4  globalstar     0         0        0     2         413\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision   2.343952  93.333333  87.452471  93.119266   99.518072\n",
      "Recall     86.602871  91.457286  93.877551  95.754717    5.196276\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train_loader = None\n",
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDLCD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/../MMT_filtered_2022\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"TRTR_5_12_2022\"#\"RTRT_v1\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "# net = load_net(cfg, seed=687129,checkpoint=5)\n",
    "net = load_net(cfg, seed=683164,checkpoint=2)\n",
    "print(net.epoch_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../MMT_filtered_2022: 100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 36 examples.\n",
      "Label: cz-3 145 examples.\n",
      "Label: falcon_9 18 examples.\n",
      "Label: globalstar 162 examples.\n",
      "Label: h-2a 46 examples.\n",
      "36 0.98\n",
      "145 0.98\n",
      "18 0.98\n",
      "162 0.98\n",
      "46 0.98\n",
      "Training set: 5\n",
      "Validation set: 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = Trainer(net)\n",
    "\n",
    "cfg.data_config.validation_split = .98\n",
    "t.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.1358275682754524\n",
      "\tAcc: 80.0\n",
      "Validation:\n",
      "\tLoss: 0.17829732219756692\n",
      "\tAcc: 50.74626865671642\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3    90        18       25     4           6\n",
      "1    falcon_9    14         0        4     0           0\n",
      "2     atlas_5    17         7        5     6           1\n",
      "3        h-2a    19         5       14     3           5\n",
      "4  globalstar    25         4       13    11         106\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3  falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision  62.937063       0.0  13.888889   6.521739   66.666667\n",
      "Recall     54.545455       0.0   8.196721  12.500000   89.830508\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 300)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load(\"c:/Users/Kyselica/Desktop/kyselica/charon_share/SDLCD_test_data.npy\")\n",
    "# test_data = np.load(\"c:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt2/atlas_5.npy\")\n",
    "print(test_data.shape)\n",
    "from src.nn.dataset import NetDataset\n",
    "\n",
    "NetDataset._normalize_data(test_data)\n",
    "test_data = torch.tensor(test_data.reshape(-1,1,300)).cuda()\n",
    "\n",
    "# n._normalize_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 300])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12]),\n",
       " tensor([0, 0, 0, 2, 4, 4, 2, 4, 2, 4, 2, 4], device='cuda:0'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "out = net(test_data)\n",
    "_, predicted = torch.max(out.data, 1)\n",
    "predicted.shape, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"c:/Users/Kyselica/Desktop/kyselica/charon_share/SDLCD_test_names.txt\", \"r\") as f:\n",
    "    names = [n.split(\"_\")[0] for n in f.read().split('\\n')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19034C',\n",
       " '18072C',\n",
       " '16037B',\n",
       " '17025B',\n",
       " '06018B',\n",
       " '15056B',\n",
       " '17063B',\n",
       " '16064B',\n",
       " '13024B',\n",
       " '98058B',\n",
       " '06054D',\n",
       " '12009B']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = torch.exp(out).detach().cpu().numpy() * 100\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: '%.10f' % x)\n",
    "df = pd.DataFrame(data, columns=cfg.data_config.labels)\n",
    "df[\"name\"] = names\n",
    "df.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a78ce341c0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABS9UlEQVR4nO3de3hTVbo/8G9SeoFCU0qhSbVyF+iUa5FSYWYUIq1wFNAzBxg8CINwqOAooEL9yUVxrMgcrzAyw4DgQdBhRlS89FhawQOWVosVCojAlHtThNIECr2Q7N8fTGLT5rKT7J3LzvfzPHmUZGXvtXd3dt6s9a61VIIgCCAiIiJSEHWgK0BEREQkNQY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESlOm0BXIBAsFgvOnz+PDh06QKVSBbo6REREJIIgCLhy5QqSk5OhVrtuownLAOf8+fNISUkJdDWIiIjIC2fOnMGtt97qskxYBjgdOnQAcPMExcXFBbg2REREJIbJZEJKSorte9yVsAxwrN1ScXFxDHCIiIhCjJj0EiYZExERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIccJyor9gYbYIKK2swYUr9ejSIQbpXTui7NRlXLhSj8TYaEAFXLzaYPf/XTrEYFj3BACwvbfl6823Yy0foXY8KVLLOrgqK8UxWrcvZr/Nyzg6B2LrKfcxutunu7+llMfh6bFKdY49qbs/z4Gn+1LiNddy/+4+kwbjddTUNSKhfTS6tHd/DsR8xp3VR47rz5drxN29Vu6/pavz4ei+7qxuct8HAnF9e0PWAOerr77CqlWrUFZWhqqqKmzfvh0TJkxw+Z5du3ZhwYIFOHToEFJSUvDss89i+vTpdmXWrFmDVatWwWAwYODAgXjzzTcxbNgw+Q5EBvkVVXhux2FUGettz6lVgEVw/974dpEAgNprTQ5fb7kdnSYGy+5LRXaazm0dnJX1hrPt3z9Qh4+/r3K5X0fvbU5sPeU+RrH7dEbK4/D0WKU6x+7482/py76UfM1Z9w9A9GfS1XbcXXPutie2jKfnTIprpDlH91q5/pbu6tXyvu6sbmLur57s19f7TCCpBEEQ8ZXqnc8//xx79+5Feno6HnjgAbcBTmVlJdLS0jBnzhw88sgjKCwsxBNPPIFPP/0UWVlZAID3338f06ZNw9q1a5GRkYHXXnsN27Ztw9GjR9GlSxdR9TKZTNBoNDAajQFZqiG/ogo5m/dDthPfgjWufuuhIXYXqaM6OCrrDU+Psfl+Abh9r5h6yn2MnuzTGamOA3B8zpxtX0w9pThPUu3Hl3MgZl/+rGcgrjkVIMn9xtPzLdW+xJwzqa4RqeslhtzfCVJd94Bn9xk5ePL9LWuAY7cjlcptgLNo0SJ8+umnqKiosD03efJk1NbWIj8/HwCQkZGBO+64A6tXrwYAWCwWpKSk4LHHHsPixYtF1SWQAY7ZImDkyiJRvx6kpAKg1cRgz6JRAOCyDs3LettE7M0xqgAkxUUDUMFgcv9eV/V0Vwdfj9ERX47bl+Nwd85abt+TevpynqTajxTnwNW+/FnPYLnmfOHp+fZ1X2LOmdTXiFT1EsNff0Nfr3tP7zNy8eT7O6iSjIuLi6HX6+2ey8rKQnFxMQCgsbERZWVldmXUajX0er2tjCMNDQ0wmUx2j0Aprazxe3AD3Pz1VmWsR2lljds6NC/rDW+PUQBgMDWIvgG5qqfcx+iIL8fty3G4O2ctt+9JPX05T1LtR4pz4Gpf/qxnsFxzvvD0fPu6LzHnTOprRKp6ieGvv6Gv172n95lgEFQBjsFgQFJSkt1zSUlJMJlMuH79Oi5evAiz2eywjMFgcLrdvLw8aDQa2yMlJUWW+otx4Yr/g5uW+xdbB2/r6u9jdLQ/uY9Rjm35chyebN+bbQbyPXJdT1Kfj1C85kKFu+MM1HmQYr+Bul/K/bkKBkEV4MglNzcXRqPR9jhz5kzA6tKlQ0zA9m3dv9g6eFtXfx+jo/3JfYxybMuX4/Bk+95sM5Dvket6kvp8hOI1FyrcHWegzoMU+w3U/VLuz1UwCKoAR6vVorq62u656upqxMXFoW3btkhMTERERITDMlqt1ul2o6OjERcXZ/cIlGHdE6DTxEC+HkrHVLiZ6T6se4LbOjQv6w1vj1EFQBsXDW2cuPe6qqfcx+iIL8fty3G4O2ctt+9JPX05T1LtR4pz4Gpf/qxnsFxzvvD0fPu6LzHnTOprRKp6ieGvv6Gv172n95lgEFQBTmZmJgoLC+2eKygoQGZmJgAgKioK6enpdmUsFgsKCwttZYJdhFplG67pr5uSdT/L7ktFhFrlsg4ty3rDm2O0llt+/y+w/H7373VXT7mP0RFfjtuX43B1zhxtX2w9fT1PUu3H13Pgbl/+rGegrjmVk//3lKfn2xeenDMprxEp6yWGP74TpLjuPb3PBANZA5yrV6+ivLwc5eXlAG4OAy8vL8fp06cB3Ow6mjZtmq38nDlz8M9//hNPP/00fvjhB/zpT3/C3/72N8yfP99WZsGCBVi3bh02bdqEI0eOICcnB3V1dZgxY4achyKp7DQd3npoCLQa+6Y8sddFfLtI2xwIjrTcjlYT02r4nrM6OCrrDWfb12li8F+/6g6di/06e6+n9ZT7GD3ZpzNSHYenxyrVOXbHn39LX/al9GtOq4nB2oeGYK0Hn0ln23F3vsVsT0wZT8+ZVNdIc47utXL8LcXUq+V93VHdxNxfPd2vL/eZQJN1mPiuXbtw9913t3r+4YcfxsaNGzF9+nScPHkSu3btsnvP/PnzcfjwYdx6661YsmRJq4n+Vq9ebZvob9CgQXjjjTeQkZEhul6BngfHijMZcyZjzmTMmYylwpmMXddHzLniTMbBP5NxUM6DE0yCJcAhIiIi8UJ2HhwiIiIiKTDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDh+CXDWrFmDbt26ISYmBhkZGSgtLXVa9q677oJKpWr1GDdunK3M9OnTW72enZ3tj0MhIiKiENBG7h28//77WLBgAdauXYuMjAy89tpryMrKwtGjR9GlS5dW5T/44AM0Njba/n3p0iUMHDgQv/nNb+zKZWdn4+2337b9Ozo6Wr6DICIiopAiewvOK6+8glmzZmHGjBlITU3F2rVr0a5dO2zYsMFh+YSEBGi1WtujoKAA7dq1axXgREdH25Xr2LGj3IdCREREIULWAKexsRFlZWXQ6/U/71Cthl6vR3FxsahtrF+/HpMnT0ZsbKzd87t27UKXLl3Qp08f5OTk4NKlS0630dDQAJPJZPcgIiIi5ZI1wLl48SLMZjOSkpLsnk9KSoLBYHD7/tLSUlRUVOCRRx6xez47OxvvvPMOCgsLsXLlSuzevRv33nsvzGazw+3k5eVBo9HYHikpKd4fFBEREQU92XNwfLF+/Xr0798fw4YNs3t+8uTJtv/v378/BgwYgJ49e2LXrl0YPXp0q+3k5uZiwYIFtn+bTCYGOURERAomawtOYmIiIiIiUF1dbfd8dXU1tFqty/fW1dXhvffew8yZM93up0ePHkhMTMTx48cdvh4dHY24uDi7BxERESmXrAFOVFQU0tPTUVhYaHvOYrGgsLAQmZmZLt+7bds2NDQ04KGHHnK7n7Nnz+LSpUvQ6XQ+15mIiIhCn+yjqBYsWIB169Zh06ZNOHLkCHJyclBXV4cZM2YAAKZNm4bc3NxW71u/fj0mTJiATp062T1/9epVPPXUU9i3bx9OnjyJwsJCjB8/Hr169UJWVpbch0NEREQhQPYcnEmTJuGnn37C0qVLYTAYMGjQIOTn59sSj0+fPg212j7OOnr0KPbs2YMvvvii1fYiIiJw4MABbNq0CbW1tUhOTsaYMWOwYsUKzoVDREREAACVIAhCoCvhbyaTCRqNBkajkfk4REREIcKT72+uRUVERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4jDAISIiIsVhgENERESKwwCHiIiIFIcBDhERESkOAxwiIiJSHAY4REREpDgMcIiIiEhxGOAQERGR4vglwFmzZg26deuGmJgYZGRkoLS01GnZjRs3QqVS2T1iYmLsygiCgKVLl0Kn06Ft27bQ6/U4duyY3IdBREREIUL2AOf999/HggULsGzZMuzfvx8DBw5EVlYWLly44PQ9cXFxqKqqsj1OnTpl9/rLL7+MN954A2vXrkVJSQliY2ORlZWF+vp6uQ+HiIiIQoDsAc4rr7yCWbNmYcaMGUhNTcXatWvRrl07bNiwwel7VCoVtFqt7ZGUlGR7TRAEvPbaa3j22Wcxfvx4DBgwAO+88w7Onz+PDz/8UO7DISIiohAga4DT2NiIsrIy6PX6n3eoVkOv16O4uNjp+65evYquXbsiJSUF48ePx6FDh2yvVVZWwmAw2G1To9EgIyPD6TYbGhpgMpnsHkRERKRcsgY4Fy9ehNlstmuBAYCkpCQYDAaH7+nTpw82bNiAjz76CJs3b4bFYsGdd96Js2fPAoDtfZ5sMy8vDxqNxvZISUnx9dCIiIgoiAXdKKrMzExMmzYNgwYNwq9//Wt88MEH6Ny5M/785z97vc3c3FwYjUbb48yZMxLWmIiIiIKNrAFOYmIiIiIiUF1dbfd8dXU1tFqtqG1ERkZi8ODBOH78OADY3ufJNqOjoxEXF2f3ICIiIuWSNcCJiopCeno6CgsLbc9ZLBYUFhYiMzNT1DbMZjMOHjwInU4HAOjevTu0Wq3dNk0mE0pKSkRvk4iIiJStjdw7WLBgAR5++GEMHToUw4YNw2uvvYa6ujrMmDEDADBt2jTccsstyMvLAwA8//zzGD58OHr16oXa2lqsWrUKp06dwiOPPALg5girJ554Ai+88AJ69+6N7t27Y8mSJUhOTsaECRPkPhwiIiIKAbIHOJMmTcJPP/2EpUuXwmAwYNCgQcjPz7clCZ8+fRpq9c8NSZcvX8asWbNgMBjQsWNHpKen4+uvv0ZqaqqtzNNPP426ujrMnj0btbW1GDlyJPLz81tNCEhEREThSSUIghDoSvibyWSCRqOB0WhkPg4REVGI8OT7O+hGURERERH5igEOERERKQ4DHCIiIlIcBjhERESkOAxwiIiISHEY4BAREZHiMMAhIiIixWGAQ0RERIrDAIeIiIgUhwEOERERKQ4DHCIiIlIcBjhERESkOAxwiIiISHEY4BAREZHiMMAhIiIixWGAQ0RERIrDAIeIiIgUhwEOERERKQ4DHCIiIlIcBjhERESkOAxwiIiISHEY4BAREZHiMMAhIiIixWGAQ0RERIrDAIeIiIgUhwEOERERKQ4DHCIiIlIcBjhERESkOAxwiIiISHEY4BAREZHiMMAhIiIixfFLgLNmzRp069YNMTExyMjIQGlpqdOy69atwy9/+Ut07NgRHTt2hF6vb1V++vTpUKlUdo/s7Gy5D4OIiIhChOwBzvvvv48FCxZg2bJl2L9/PwYOHIisrCxcuHDBYfldu3ZhypQp+PLLL1FcXIyUlBSMGTMG586dsyuXnZ2Nqqoq22Pr1q1yHwoRERGFCJUgCIKcO8jIyMAdd9yB1atXAwAsFgtSUlLw2GOPYfHixW7fbzab0bFjR6xevRrTpk0DcLMFp7a2Fh9++KFXdTKZTNBoNDAajYiLi/NqG0RERORfnnx/y9qC09jYiLKyMuj1+p93qFZDr9ejuLhY1DauXbuGpqYmJCQk2D2/a9cudOnSBX369EFOTg4uXbrkdBsNDQ0wmUx2DyIiIlIuWQOcixcvwmw2Iykpye75pKQkGAwGUdtYtGgRkpOT7YKk7OxsvPPOOygsLMTKlSuxe/du3HvvvTCbzQ63kZeXB41GY3ukpKR4f1BEREQU9NoEugKuvPTSS3jvvfewa9cuxMTE2J6fPHmy7f/79++PAQMGoGfPnti1axdGjx7daju5ublYsGCB7d8mk4lBDhERkYLJ2oKTmJiIiIgIVFdX2z1fXV0NrVbr8r1//OMf8dJLL+GLL77AgAEDXJbt0aMHEhMTcfz4cYevR0dHIy4uzu5BREREyiVrgBMVFYX09HQUFhbanrNYLCgsLERmZqbT97388stYsWIF8vPzMXToULf7OXv2LC5dugSdTidJvYmIiCi0yT5MfMGCBVi3bh02bdqEI0eOICcnB3V1dZgxYwYAYNq0acjNzbWVX7lyJZYsWYINGzagW7duMBgMMBgMuHr1KgDg6tWreOqpp7Bv3z6cPHkShYWFGD9+PHr16oWsrCy5D4eIiIhCgOw5OJMmTcJPP/2EpUuXwmAwYNCgQcjPz7clHp8+fRpq9c9x1ltvvYXGxkb8+7//u912li1bhuXLlyMiIgIHDhzApk2bUFtbi+TkZIwZMwYrVqxAdHS03IdDREREIUD2eXCCEefBISIiCj1BMw8OERERUSAwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIcRjgEBERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIcRjgEBERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIcRjgEBERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUpw2ga4AERHJy2wRUFpZgwtX6tGlQwyGdU9AhFoV6GoRycovLThr1qxBt27dEBMTg4yMDJSWlrosv23bNvTt2xcxMTHo378/PvvsM7vXBUHA0qVLodPp0LZtW+j1ehw7dkzOQyAiCkn5FVUYubIIU9btw+PvlWPKun0YubII+RVVga4akaxkD3Def/99LFiwAMuWLcP+/fsxcOBAZGVl4cKFCw7Lf/3115gyZQpmzpyJ7777DhMmTMCECRNQUVFhK/Pyyy/jjTfewNq1a1FSUoLY2FhkZWWhvr5e7sMhIgoZ+RVVyNm8H1VG+3ujwViPnM37GeSQoqkEQRDk3EFGRgbuuOMOrF69GgBgsViQkpKCxx57DIsXL25VftKkSairq8Mnn3xie2748OEYNGgQ1q5dC0EQkJycjIULF+LJJ58EABiNRiQlJWHjxo2YPHmy2zqZTCZoNBoYjUbExcVJdKRERMHDbBEwcmVRq+DGSgVAq4nBnkWj2F1FIcOT729ZW3AaGxtRVlYGvV7/8w7Vauj1ehQXFzt8T3FxsV15AMjKyrKVr6yshMFgsCuj0WiQkZHhdJsNDQ0wmUx2DyIiJSutrHEa3ACAAKDKWI/Syhr/VYrIj2QNcC5evAiz2YykpCS755OSkmAwGBy+x2AwuCxv/a8n28zLy4NGo7E9UlJSvDoeIqJQceGKuC57seWIQk1YDBPPzc2F0Wi0Pc6cORPoKhERyapLhxhJyxGFGlkDnMTERERERKC6utru+erqami1Wofv0Wq1Lstb/+vJNqOjoxEXF2f3ICJSsmHdE6DTxMBZdo0KgE5zc8g4kRLJGuBERUUhPT0dhYWFtucsFgsKCwuRmZnp8D2ZmZl25QGgoKDAVr579+7QarV2ZUwmE0pKSpxuk4go3ESoVVh2XyoAtApyrP9edl8qE4xJsWTvolqwYAHWrVuHTZs24ciRI8jJyUFdXR1mzJgBAJg2bRpyc3Nt5R9//HHk5+fjv//7v/HDDz9g+fLl+PbbbzFv3jwAgEqlwhNPPIEXXngBH3/8MQ4ePIhp06YhOTkZEyZMkPtwiIhCRnaaDm89NARajX03lFYTg7ceGoLsNF2AakZWZouA4hOX8FH5ORSfuASzRdaBzWFF9pmMJ02ahJ9++glLly6FwWDAoEGDkJ+fb0sSPn36NNTqn+OsO++8E1u2bMGzzz6LZ555Br1798aHH36ItLQ0W5mnn34adXV1mD17NmprazFy5Ejk5+cjJoZ9yUREzWWn6XBPqpYzGQeh/IoqPLfjsN1oN50mBsvuS2XwKQHZ58EJRpwHh4iIAsk6CWPLL2Br2MkWNseCZh4cIiIisme2CHhux+FWwQ0A23PP7TjM7iofMcAhIiLyI07C6B8McIiIiPyIkzD6BwMcIiIiP+IkjP4h+ygqIiLyP7NF4MipIGWdhNFgrHeYh2NdCJWTMPqGAQ4RkcJw+HFws07CmLN5P1SAXZDDSRilwy4qIiIFsQ4/bpnEajDWI2fzfuRXVAWoZtQcJ2GUH1twiIgUwt3wYxVuDj++J1XL1oEgwEkY5cUAh4hIITwZfpzZs5P/KkZORahV/FvIhAEOEZFCcPhxaGJCuDwY4BARKQSHH4ceJoTLh0nGREQKYR1+7Oy3vwo3vzw5/Dg4MCFcXgxwiIgUwjr8GECrIIfDj4ML16OSHwMcIiIF4fDj0LDvn5e4HpXMmINDRKQwzYcfG4zXUVPXiIT20dC0jYLZIrAFJ8DyK6qw+B8HRZVlQrj3GOAQESlQhFoF4/VGvPy/R5nAGkSseTdiO56YEO49dlERESkQE1iDj6u8m5aYEO47BjhERArDBNbg5G4ixpaYEO4bBjhERArjyYzG5D9i82ni20UyIVwCzMEhIlIYzmgcnMTm06yZMgQjeifKXBvlYwsOEZHCcEbj4CR2IsbhXJtKEgxwiIgUhjMaBydOxOhfDHCIiBSGX6TBixMx+o9KEISwS6M3mUzQaDQwGo2Ii4sLdHWIiGTBhRyDF1cQ944n398McBjgEJGC8YuUlMST72+OoiIiUrAItQqZTFqlMMQcHCIiIlIcBjhERESkOAxwiIiISHGYg0NERORHTPz2DwY4REREfsKh+/4jaxdVTU0Npk6diri4OMTHx2PmzJm4evWqy/KPPfYY+vTpg7Zt2+K2227D73//exiNRrtyKpWq1eO9996T81CIiIh8kl9RhZzN+1sthGow1iNn837kV1QFqGbKJGsLztSpU1FVVYWCggI0NTVhxowZmD17NrZs2eKw/Pnz53H+/Hn88Y9/RGpqKk6dOoU5c+bg/Pnz+Pvf/25X9u2330Z2drbt3/Hx8XIeChERkdfMFgHP7TgMRxPPCbg5w/RzOw7jnlQtu6skIttEf0eOHEFqaiq++eYbDB06FACQn5+PsWPH4uzZs0hOTha1nW3btuGhhx5CXV0d2rS5GY+pVCps374dEyZM8KpunOiPiMIRcz8Cp/jEJUxZt89tua2zhnPeIheCYqK/4uJixMfH24IbANDr9VCr1SgpKcHEiRNFbcd6ENbgxmru3Ll45JFH0KNHD8yZMwczZsyASuX4g9rQ0ICGhgbbv00mkxdHREQUupj7EVgXrtS7L+RBOXJPthwcg8GALl262D3Xpk0bJCQkwGAwiNrGxYsXsWLFCsyePdvu+eeffx5/+9vfUFBQgAcffBCPPvoo3nzzTafbycvLg0ajsT1SUlI8PyAiohDF3I/A69Ihxn0hD8qRex4HOIsXL3aY5Nv88cMPP/hcMZPJhHHjxiE1NRXLly+3e23JkiUYMWIEBg8ejEWLFuHpp5/GqlWrnG4rNzcXRqPR9jhz5ozP9SMiCgXucj+Am7kfZkvYLUvoV8O6J0CniWm1uruVCjdb1IZ1T/BntRTN4y6qhQsXYvr06S7L9OjRA1qtFhcuXLB7/saNG6ipqYFWq3X5/itXriA7OxsdOnTA9u3bERkZ6bJ8RkYGVqxYgYaGBkRHR7d6PTo62uHzRERKV1pZ06rlpjkBQJWxHqWVNcz9kFGEWoVl96UiZ/N+qAC7gNMa9Cy7L5U5URLyOMDp3LkzOnfu7LZcZmYmamtrUVZWhvT0dABAUVERLBYLMjIynL7PZDIhKysL0dHR+PjjjxET4765rry8HB07dmQQQ0SyCOXkXOZ+BI/sNB3eemhIq1woLXOhZCFbknG/fv2QnZ2NWbNmYe3atWhqasK8efMwefJk2wiqc+fOYfTo0XjnnXcwbNgwmEwmjBkzBteuXcPmzZthMplsCcGdO3dGREQEduzYgerqagwfPhwxMTEoKCjAiy++iCeffFKuQyGiMBbqybnM/Qgu2Wk63JOqDdmAOZTIOg/Ou+++i3nz5mH06NFQq9V48MEH8cYbb9heb2pqwtGjR3Ht2jUAwP79+1FSUgIA6NWrl922Kisr0a1bN0RGRmLNmjWYP38+BEFAr1698Morr2DWrFlyHgoRhSFrcm7L7BRrcu5bDw0J+iDHmvthMNY7zMNR4WYLAnM//CdCrWJ3oB/INg9OMOM8OETkjtkiYOTKIqf5K9bAYM+iUUH/69saqAGOcz9CIVAjAjz7/uZq4kREDniSnBvsrLkfWo19N5RWE8PghhSLi20SETkQism5rpKhmftBUgv25HsGOEREDpy8WCeqXLAk54pJhm6e+xHsX04U3EIh+Z45OMzBIaIW8iuqMOdfOSvOBFMOjrNkaGc5NqHw5UTByWwRsLroOF7d+WOr1/yR08UcHCIiL1ln/hUjGCZm83SmYi7bQO6YLQKKT1zCR+XnUHzikt21M+KlQofBDRB8M2Ozi4qIqBl3ycVWvx/dOyhaOzxJhh7WPcFlMKTCzS+ne1K1AQ/cKDActe7Ft43EyN6J+PRAlcNrp7lgmhmbLThERM2ITRre9PXJoGjt8CQZWkkjw0h6zlr3aq834RMRwU1zwZB8zwCHiKgZsUnDtdebMGfzfry+80e/N8c370K4eKVB1Hu6dIgJyZFh5B+uujq9EQzJ9+yiIiJqxt3Mvy29uvMYtpaewfL7/ZOg66gLQa0CnMVYzWcqFtsyEwxfTuRfYrtm3QmmmbHZgkNEIc9ZUqQ3rKs+e8Jgqseczfvx3McVPu/fFWddCK6CG+DnZGhr8OYsu0aFm6OpguHLifxLyla7YEi+B9iCQ0QhTo4hz9aZfxf/4yBqrzeJft/bX5/C21+fkmXItZguhJYtOS1XqbYGbzmb90MFx8s2BMuXE/lXYvton7cRbFMNcB4cGefB4URaRPLydP4XT+09fhFT/1ri1XtVEuy/ueITlzBl3T635ZaM64fEDtEu7zmcBycwgvU7Ib+iCss/PgSDSVw+lyPz9b0xb1Rv2Y/Hk+9vtuBIzHoBFxw24MPy86ipa7S9ptPEYMm4fugYGx10FzhRqGm8YcEz2yvczv/iy5Dn4T06QaeJ8To3Qcoh12K7EBI7RGP8oFtcluGyDfJyFMgUHDYEZVDp7EeCJ+brb8fj+t6S1UkqDHAk5OhXUXNVxno8uuU7u+eC4QInCjX5FVV4ZvtB1NS57j6qMtZj34lLUKtVXn2RW7t03M1q7IjU84GITfwVW675sg0kHYfzyLSLRO211teqdXJFZy19crf4SDFyShsXjXmjeklWJykxwJGIt1FwlfFmcuLMEd2gT9XyVxSRG55+1mb9z7e41mi2/dvTHxXZaTrM1/fGqzuPeVFb6ZI3xYzuSoiNRHrXjpLsjzzn7Np0FNwAridX9Ec3ohQjp5bf/4ug/c7iKCoJSBEFr997ElPW7cPIlUVBMXkYUTCxjpLavv+s024pZ5oHN4B3SxLMG9Ub2jjvhk5LNeS6+eguZ18nNXVN+PWqL3kPCQBvvwdaTq5otgh4fecxzPHDchq+Bt/z9bcHde8DAxwJSDV/AMD1YIgA+2Hfr+88hhEvFWHKun2Y/7fv7fLavCH86/HM9oNovGER9Z4ItQrL7091Glg4I3WLinV0l1bjPGjiPSQwfP0euHCl3u9rPfkSfAdz15QVAxwJSDl/QLAtVkbkb/kVVRi58mZA8/h75Xh1548wmKSfWbemrgnD8wrx2YHzoubQsQYXOhfBhaN9SN2ikp2mw+6n7kZCbJTD13kPCQxfvwdOXryGnM373Y5kknI5DXfzIjmi+tfDVdeUlPNS+YI5OBKQetbPYFqsjMifpBjR4YmausZWif/auGhMGXYbuiXGtkrsbD76yNFISUfcJZJ6o+zUZZf75T3E/3xtDdlaetrvaz25mxdJQOsE6ZZzK7UUTFMQMMCRgDUKlqqbyorrwVA4sI4UMRivY8WnR/wW3DhjMDXYJRS3vDlbRx9l9uyE/zcuFaWVNcivOI93ih1/QcmxSjfXlAo+ni7x0dzkO27Da4WeJbFL9cPa2jLZMiixBjJipxMwWwSsLjrusHtNjiBfDAY4EvBlKKkrJy9ek3R7RMHG3dQKwcDVzTlCrYLxeiM2FZ92uY1gHzJOvnPVGuLODQ+6cORY68ndvEiurllrYLNhzz9hrL/hsIwcQb4YzMGRSHaaDjPu7CbpNl/b+WOrvvtg6dsk8pWzdZWCjaucFuvIGbGkHjLu65pSvJ9IS0wSuGOenXc5ltOwtkyOH3QLMnt2ErX9/IoqpL9QgFd3/ug0uLGSMndILLbgSCS/ogoffX9O0m1aR3qM6puEqDZqfHagCs9+VNFqdmROFEjBytlEZWaLgMUfHAx4d5RYzlpgPB05I/WQcV/WlAqmXAklsbaGrC46jr98dQJ1LaYpcCSzRyL+sf+c2+6tYPr75FdUedVr4c9uUwY4EpAzMbKmrgnpLxSgW6d2OHjO1Op160SB1nVAAHD6dQoKrr5AjxquOJ38LJi1vDl7crOWepVud7kTrr4End2zApUroTQFhw14beePbr8TrN1Nw3t2ctu95a+1nsTwtOWyOX92mzLA8ZEUk/y5c6X+hsPgprlXdx7D23tPAir7WTODKeKn8OHsC9QakEe3kecm7Wzkh1Ra3pw9uVnL0a3gzZpSru5ZgcqVUBKx3wktW9qcBazBeA/3Zs4fOXKH3GGA4yMpJ/nzVe11z9c6IZKamBt8ww15fhK0HPnxeUUV3ik+5fN2nd2cxYycUQF4fHRvNNywoPjEJclbVT1dU8rdPYtDzH0j9jshITYKf5iYZndfDpVFUL3pZhIgT5DvCgMcH4n9Q2vaRsLoIACRmye/yORe2I3CQyCD/j/++0CM6J0I4OeRH74GOK5yWsSMnNG0i7QbAhzoX+QcYi4vseft2XH9HF4D/lwE1dt7vjfdTL8b0Y3z4IQasX/oP/12iG1F48TYaEAFXLzagJMXr4nqq/WF9RfZvhOXbDf/lphwSFIwWwTsPX4xYPu/WGc/C6wvc5NYuctpcda1YO0ma9lVJmWrqjdfUBxiLi+x5+10zXWZa+KaL/d8bz5X96Rqfaitdxjg+MjdH7p5EpmzG08fbXs8s/0gaurkbeGZu2U/Xnqwf6uLlwmHJIVgmNOm5ZeLL3OTADfXktr91N2IauN6Ro2WXQuJsdFYuO17AK0/01LluXj7BSX2nuXPXAklGdY9Adq4aLdLLrz3zWnMG9UrIK3kvt7zm3+u3Ank9cR5cHzkaoVfscM1s9N02Jerd7q2jFRqrze1WoTPXcKhACD3gwP4vx9/4lwZ5FSg57RxNe+L93OT3BzFWHbqsqiyzecRUatVLtfP8nVOEGfnW8xCm1Lcs8i5CLUKU4bd5racJ39/KecrcnfPB8StYyZmbbZAX09swZGAL8M1raLaqPHixDTZ1+ERYP/LUUy+xOVrN/CfG0pt/2bXFTXnj5GEroi5iTpK3qyqvY4F2753u31vclHkzHORYhSUFPcscq5bYqyocmL+/lKnD0iZZO5ubbZAX0+yBjg1NTV47LHHsGPHDqjVajz44IN4/fXX0b59e6fvueuuu7B792675/7rv/4La9eutf379OnTyMnJwZdffon27dvj4YcfRl5eHtq0CVy8JkX2u7ObjtSqjPXYuLcS00d09+oGy64rak7KpOKkDlF4ZdJgXDDVY8WnR3C5rtFt4CT2JtoyebP4xCVRdfImF+XkxTrZti3VF1SojNgJRVLlOcmRPiB18O1obbZguZ5kjQimTp2KqqoqFBQUoKmpCTNmzMDs2bOxZcsWl++bNWsWnn/+edu/27VrZ/t/s9mMcePGQavV4uuvv0ZVVRWmTZuGyMhIvPjii7IdixhSZL+7i4gTYiMxcdAtiGsbhQ17K70embXi0yP4655KTL4jxeP3cq4Map7ceqz6qs/bs15Bz41Pw4heNxPh20ZFuMydmTmiG/SpWq9vonLlopgtAraWul6bCvB+4j8pv6D8OWInnEhxbck1X5GcSebBdj3JFuAcOXIE+fn5+OabbzB06FAAwJtvvomxY8fij3/8I5KTk52+t127dtBqHWdcf/HFFzh8+DB27tyJpKQkDBo0CCtWrMCiRYuwfPlyREXJm8fiD2Ij4qHdOmLqX0u83o/BWI9Xdx5DfLtIGK81edTFwLkywo81qHEUeIuREBvl9D2OWmHknvhMiuUOHCmtrHGbYArcXEHam8CMo6CCnxTXllQtdS1H2g1KiXf5WVRSkrlsAU5xcTHi4+NtwQ0A6PV6qNVqlJSUYOLEiU7f++6772Lz5s3QarW47777sGTJElsrTnFxMfr374+kpCRb+aysLOTk5ODQoUMYPHhwq+01NDSgoeHnG47J5HpW4GDiKiIe3qOTT0Ngrb8CfMG5MsKDryOkEmIjsXfRKJSfqW01VYKrpmy5u1HkyEUR+5loMpthtggeHwtHQYUGX68tsdeRweh8uLmjz61aBTjLHw50UrDUZAtwDAYDunTpYr+zNm2QkJAAg8Hg9H2//e1v0bVrVyQnJ+PAgQNYtGgRjh49ig8++MC23ebBDQDbv51tNy8vD88995wvhxOUfB0Ci3+9p/ZaEx4ccgvyKwyiFoZrjr8Slc1sEbC66Dhe3fmjT9upqWvCqP/ehWX3pWL8oFs8eq/czd5SB1FiPxOrvzyBf+w/53EgJVfLE0nPl2tL7HW04tMjaBsV0Wo/l+saMXdL6/wdV4OjAp0ULDWPA5zFixdj5cqVLsscOXLE6wrNnj3b9v/9+/eHTqfD6NGjceLECfTs2dOrbebm5mLBggW2f5tMJqSkeJ57EoykSkz+x37PV0KPbxfJX4kKZQ1sNuz5J4z1NyTZZjAnp0sZRHkyCZp1ba4//XYwxg5w3m0PtO5qWPPbIVjxKUdBBTtvry2x19HlukbM2by/1fprapVnP3rFzvkUSjwOcBYuXIjp06e7LNOjRw9otVpcuHDB7vkbN26gpqbGaX6NIxkZGQCA48ePo2fPntBqtSgtLbUrU11dDQBOtxsdHY3o6GjR+ww1ziYZqzZ5P3urGLXXmlBw2MCbqcLkV1Rh8QcHJV+sMlyS071pWZ275TtMP3kZY37hOGna2VDhJeP6oWNsdNCMWiHpiJ1Mz3p9tfy8ejpVjnXOJyXlVHocqnXu3Bl9+/Z1+YiKikJmZiZqa2tRVlZme29RUREsFostaBGjvLwcAKDT3fwSzczMxMGDB+2Cp4KCAsTFxSE1NdXTw1GM5pOMjeidiOX3p8o+L4n1y4oT/ylHfkUV5mzeL8tK3IDvE9yFCk8nFxQAvP31SUxZtw8jVxbZTdTnalK/uVu+g/F6I8YPugWZLmZLp9BkvY4SYiP9sr+Cw87TR0KRbG1R/fr1Q3Z2NmbNmoXS0lLs3bsX8+bNw+TJk20jqM6dO4e+ffvaWmROnDiBFStWoKysDCdPnsTHH3+MadOm4Ve/+hUGDBgAABgzZgxSU1Pxn//5n/j+++/xv//7v3j22Wcxd+5cRbfSeCo7TYf5+t6y7iNcvqzChXVYqj+EQ3J6dpoOexaNwry7e3n0vuazEYuZaXz5x4f4I0PBstN0WPJvv/DLvjbsPelyFuxQI2tn27vvvou+ffti9OjRGDt2LEaOHIm//OUvttebmppw9OhRXLt2DQAQFRWFnTt3YsyYMejbty8WLlyIBx98EDt27LC9JyIiAp988gkiIiKQmZmJhx56CNOmTbObN4duEjubpq/C4csqHPhzFfBwSU6PUKts8/qI1Xy6/H3/vOT2b2IwNWB10XEva3iTlEsBkPS0cf75vCitVV7Wif4SEhJcTurXrVs3CMLPJzIlJaXVLMaOdO3aFZ999pkkdVQyf32JJMay5UwJ/BWoejvBXai6XOd+TpyWrK2jX4tcmf3VnT+ij7a9V/lwUi8FQNLzZvVubyhtfjPlpEtTK9YPhdy98gu3fa+oZs1w5Y+AWIXwGsJstghY8an3o0o3fn1SdFlvfnn7smgn+U/zBVL9QSmt8gxwFMxfH4pqE2+GSiB3QNyxXWRQDhGXk6/dfp7MS+VpPpxUq0qTf2Sn6TD7V939si+ldCEzwFE4f2Th82aoDFIFxC0bZ+LbRmK+vje+ffaesApuAP//EvZkf54sBUDuyZ3HZLYI+Ph7eX9EqqCsLuTALb9NfpOdpsP1Jgvmv18u2z6U1ncbrqwB8eJ/HEStBwu5ztf3RrfEWHTpEIP0rh1Rduoy52aB/38Je7I/qVeVDmf+yGPy1yAAJXUhM8AJE/7Kwi84bGCAE+Ky03ToEBMpaiHXTrFR+MPEtFY3cV4DN/krOdSb9ae4aKc0rHlMLf++Us/cLXegqcTEcnZRhQl/JRwrbR6FcGS2CIBws2vJlYTYSBTnjlbUDVFqzbv95Prsebv+lLt7gtK6K+TgzzwmOQPN+fre2LNolOI+ywxwwoSrG63UN17m4oSu/IoqjFxZhKnrS5x2Uan+9XhxYn9FrVsjF2ezGkv1uUuIjfKqlUDMPUFJ3RVy8Gcek68/UttHt0F8O/sfLTpNDNY+NASP629X5N+ZXVRhxNnCnNYF+gB4nHvhCHNxQpOzpvaWuKCj5xytKj0oJR4jVhahpq7Rp20/O66f138Ld/cE/o1d82cek9i1qRxJiI3Evlw9ItQqr1Y2D1UMcMKMoxtt84tcbO6FO8zFCS2umtqt4ttGYs3UIRjeg2seecPRqtIvTkzDHC++sJrTatr69H539wRyzt95TM4CUmesf8Hmra3hdF9mgBOGHN1orYb36CRJUuTfy85i8b392IURIsQsCVB7vQlqlYpffBLKTtNh5ohuWL/3pMfv9Sax2BlX9wRyTkwSuTYuWtI8puYBacFhAz4sP++0FTDcW+IY4JCd5s2gKsDrIMdUfwPD8wrxooMRNhRc8iuqsPgfB0WV5ZBh6elTtV4FOABzZAJNzP2y/oYFBYcNkt4HrQFpZs9O+H/jUm2tb4mx0YAKuHi1gS1xAFRC88WgwoTJZIJGo4HRaERcXFygqxOUHM3r4K2ZI7pBn6oN+w9bMBKbd2O1ddZw/tKXmNki4I4/FKCmTnzum9xDes0WgV1WHsivqMLiDw6i9lrrv6H1rIXbLN5y8eT7mwEOAxynrDc5g/E6Vnx6BJfrGn3qtvLkpswbrPzMFgEjVxaJ7svXamKwZ9Eo/h1k8NmB83h0y3eiys7X98a8Ub1l+ztw8U3PmS0CRrxUBIPJ8WeJnx/pePL9zS4qcqp5v3zbqAifu63ETnzFG6x/eDozKrtD5DN2QDL+62wt/vxVpdMyHdtFIu+B/rJ+Bvw1aZ3SlFbWOA1uAM70HijMACVRnM3l4QlnE181X8Pl9Z3HuLqxzKzn+3OR5zI+DBfJDITcsan402+HICE2yu55f63lxcU3vcdlL4ITW3BItJbDSf/vx4v4+/6zHm3D+ktm495KTB/RHQWHDaJyfQTcbOZ9bsdh3JOqZUuClz47UIVnP6rwaO6VNVOGYETvRBlrRVZjB+iQlRaYIdueTFrHVgh7XPYiODHAIY+0HE7qaYBjteLTI3jzy+MOk/Kc4Q3WN3mfHXbZBdKSNW9gOM+1XwVqyDZbIbznbri4lEP6STx2UZHXfP014klw05zBeN3WpVV84hKbzEX4pPy8x8ENwLybcCL285wYGy1zTUIPl70IThxFxVFUXrOOwpF7peSWEmKj7LpYmIDs2mcHzmPulu88+hvxnIYfsZ9nbVwMlt/Pa8MRDpCQH4eJu8EARzqezqMiJ+vwWQAcYv4v+RVVHi8FIPcwZApe1s8z4Hy0JOd1cY1TXMiLAY4bDHCkZZ0J19dFOqXQLioCapUKVxtu2J4L1/l3PJnnpjkd5+sIa/kVVVj+8SEYTA1Oy3BeFwoUzoNDfpWdppNskU5fXWs0t3quyliPOZv3u22ZUFrzsqfz3FgxkTu8ifk8M+GfQgGTjEkS1kU6g/m33Ks7j2HES0UO59KxNs0raf6dnYcNXr+XI2XC28Wrzltvmivw4RojkhsDHJKEq1EEwcRgutmas2LHIdsILCVOcGa2CNhefs7r93O+jvAm9u+/Ye/JkAz+KTwwwCHJSDHbsb+s33sSU9btw8iVRVhddEz0BGehorSyxqPFG61UuNktx/k6wpt1Xhcxntl+EI03LDLXiMhzDHBIUtlpOuxZNApbZw3Hq/8xEAmxUcHdomOsx6s7j4kqG0rdNt7UlfN1kFXzFll3auqaMDyvkC05FHQY4JDkrDOxThxyK16cmAYgeLutPOl0CqVum5MX6zx+j1YTw6G/ZJOdpsPMEd1Ela2pawzZXDVSLo6iIllZu61ajk5qHx2Bqw2tRzwFo1CbZj2/okpUq5Q2Lhr//R+DcPFqQ8gPiSd56FO1WL/3pOjyXCuOggkDHJJdy0U6rV+mYhfa9CcV7Ft1Qq3bxmwRsPiDg27LqQAsv/8XGNGLi2iSc+7WWGqOQ8cp2LCLivzC2m01ftAtyOzZCRFqlS1fZ97dvQJdPQDAfP3trRKkQ63bZnXRMVFrfD2hvz1kjokCx5NcHKtQylUjZWMLDgVUhFqFEb0SsfrL427Lzru7FzJ7dMI3J2vwWqG4xGCxEmIjkXNXT8wb1StkZzI2WwS8LbI7oVtiO3krQ4ph7WZeuO171InoVg6lXDVSNllbcGpqajB16lTExcUhPj4eM2fOxNWrV52WP3nyJFQqlcPHtm3bbOUcvf7ee+/JeSgkI2szuLMwwjp0ef49t2NE70Q8cc/tWPvQkFbDWJM6RKF9tHcxe01dE4b9YSdWFx3DsO4Jdi1NocBsEbBxb6Xo5TL4JUSechfccIoBCjayrkV17733oqqqCn/+85/R1NSEGTNm4I477sCWLVscljebzfjpp5/snvvLX/6CVatWoaqqCu3bt79ZaZUKb7/9NrKzs23l4uPjERMj7qbNtaiCj7NF/lwt7Odo3aiCwwa3iwW6E98uEi890N9h3lAwBjyOlphwJb5dJMqevScoj4WCj9g1zVTgApwkv6BYbPPIkSNITU3FN998g6FDhwIA8vPzMXbsWJw9exbJycmitjN48GAMGTIE69ev/7nSKhW2b9+OCRMmeFU3BjjBSaq1oDz9wncmNioCdc3WtgrGdam8Wc19vv52PK7vLVudSFmKT1zClHX73JbjdUX+EBSLbRYXFyM+Pt4W3ACAXq+HWq1GSUkJJk6c6HYbZWVlKC8vx5o1a1q9NnfuXDzyyCPo0aMH5syZgxkzZkClcvyLtKGhAQ0NP6+tYjKZvDgikpuz0VaetjQ0347BeB0rPj2Cy3WNHrfo1LVYuNO6LlXzX6mBXH3c1RITzsS3i8S8UcGR1E2hQWzSMPO6KNjIFuAYDAZ06dLFfmdt2iAhIQEGg7gF2tavX49+/frhzjvvtHv++eefx6hRo9CuXTt88cUXePTRR3H16lX8/ve/d7idvLw8PPfcc94dCPmVdbSVlNtpGxWBnM37Ww0B95SAm83w1rk+HA1z92crjzerhb/0QH92TZFHxOZrMa+Lgo3HScaLFy92mghsffzwww8+V+z69evYsmULZs6c2eq1JUuWYMSIERg8eDAWLVqEp59+GqtWrXK6rdzcXBiNRtvjzJkzPtePQoeUa2RZ5/pYXXQ8oKuPmy0C9h6/KLq8ThODtcyPIC+4GwQA3ByFmN61o9/qRCSGxzk4P/30Ey5duuSyTI8ePbB582YsXLgQly9ftj1/48YNxMTEYNu2bW67qP7nf/4HM2fOxLlz59C5c2eXZT/99FP827/9G+rr6xEdHe32GJiDE57MFgFvFB7D6xIMMY9vG+l0xJJ15uM9i0bJ0lriaY7RknH9MH1Ed7bckNecDQJoLiE2EhMH3QJ9qjZoE/LlEsiu6nAjaw5O586d3QYcAJCZmYna2lqUlZUhPT0dAFBUVASLxYKMjAy371+/fj3uv/9+UfsqLy9Hx44dRQU3FN7+9q00rXeuhmPLOaOrp0nFOk0MgxvymbMlV5qrqWvC+r0nsX7vyaBMyJeLVIMjSHqyzYPTr18/ZGdnY9asWSgtLcXevXsxb948TJ482TaC6ty5c+jbty9KS0vt3nv8+HF89dVXeOSRR1ptd8eOHfjrX/+KiooKHD9+HG+99RZefPFFPPbYY3IdCimENzkrjsS3jRRVTuoZXb1JKp58x20MbkgS2Wk67H7qbiTERrkt66+u2kD77EAV5gSwq5pck3Wiv3fffRd9+/bF6NGjMXbsWIwcORJ/+ctfbK83NTXh6NGjuHbtmt37NmzYgFtvvRVjxoxptc3IyEisWbMGmZmZGDRoEP785z/jlVdewbJly+Q8FFIAqQKOO3uKm8hM6qRLbwI0jmwhKZWduoyauka35axB+HM7DsNskW2qtYD67MB5zNu63+Fr4XD8oUDWpRoSEhKcTuoHAN26dYOjFKAXX3wRL774osP3ZGdn203wRySWrwGHSgUIAvBZRbXrcpBn9XFvAjSObCEpeXINWrtq9524hBG9lbWoa35FFR7d8p3LMlx8NPC42CaFDTGjQRyJanPzYyImHV/q1cfNFgHFJy7ho/JzuHilwf0bmuG0+SQ1bwLmuVuU1VVjtghY/MFB0eW5+GjgcLFNChvWlZE9nRMnwoM4RSthcqGj5EVP6i1VkEVkZf2RYDDWi74Oa683Yc7m/Ziv7415o3qH/DW5uugYaq+JW/MNYCtqILEFh8KKN3PiXG+yuC0z7+5e2DprOPYsGiVZcONonh2xXyrz9bdzBAdJzvojwRuv7jyGES8VhXRrjtki4O29J0WXZytqYDHAobCTnabDnkWjsHXWcPxuRDcA8LjbqqXeSe0lW33cm9FSzWnjorkcA8nG+iNB58XEmQZTPeZs3o/Xd/4Yksm3pZU1LqeIaImtqIHFLioKS9alHDJ7dsKw7gmtuoLUKsCT+29irHRzMHk7nN16G11+/y94UyVZNV/v7X8PVWHj16c8ev+rO49hw96T+N2IbiHVbSU2n0alAtZM4czhgcYWHAp7zVt0Xp88CEvG9fMouAGAhdu+l6zp3dukRK0mxm4hUCI5WX8kZP3Cu+vNeL0Jr+48hvQXCkKm20psPs3vR/XG2AH8HAYaAxwi/HyzHj/oFiR28Lw1Rsqmd2+SEufre0uW/0PkCV9HCdVeu5mEHApBjpiRmPHtIvH70b39VidyjgEOUQu+jHp4decxDH2hACt2HELxiUteBTvWm6hYKgDvfcMFZCkwpBoltPiDg0Gfl9M8ydpZkPPSA/1DpstN6RjgELXg7Xw5Vpev3VyTZ8q6fRi50vNRIxFqFZaM6ye6fPMJxYj8zdfPi1XttSasLjre6vnmc0F5+6NBSs5GYuo0MVjLLuKgwiRjoha8nS/HEeuaNJ7mxnT0ImmZE4pRIEj5efnL/51Azl09bZNrButCls2TrLmCePBiCw6RA97Ml+OIN2vSmC0C9h6/6PG+OKEYBYqzz4unX/d1DWYMzyvEZwfO4/Wdx4JyIUtri9InB84DAP5tQLJkU0SQtFSCo8WgFM5kMkGj0cBoNCIuLi7Q1aEgZrYIKK2swd7jP2H1lyd82tbWWcPdrknj6BerO9a1r/YsGsWbLAWU9fNibdVI79oRb+06gVd3/ijpfgJ1zQdri1I48eT7my04RC5YR1fNv6ePVxObNeeuC8nZ7MWuSL32FZEvmo9GzOzZCVFt1Hhc3xtrHxqC2OgIyfYTiLwzZ5/PQLcokXMMcIhEsOYZ+BJCuOpC8nb2Ys59Q6EgO02H75aMQftoadM+/ZV35urz6U03NPkHAxwikXyZot7dmjSezF6cEBuJmSO6Sbr2FZHcotqo8cffDPB5tFVz/so7c/f55EjG4MRRVEQeaDl64p8/1eHNomNuZz6eNDTF5es7DxtE7X/e3T0x/54+7I6ikGT9kfDM9oOoqRO/ppMjCbGRSO/aUaKauSa2pYgjGYMLW3CIPNQ8z2B4j06ilnV4rfBYqzlxrKMxnt9xCOtFrlA8oldnBjcU0rLTdNiXq0dCbJRP26mpa8KvV33pl9wXsS1FHMkYXBjgEPnAk19szZMR8yuqMHJlEaas24cNIoMbALhc1+hFLYmCS1QbNV6cmOZzd5W/EnzdTWaogvtuaPI/BjhEPvDkF5u1oWfxPw44nN9DjBWfMpGRlMHaXZUQG+n1NuRK8HU0e/LkO25zmGTMkYzBizk4RD6w/rIzGOtFjYASANRev+H1/qyJjO7m0yEKBdlpOozqm4TheYWo8bJ1snmCrxSfC0dz3ahVcNoVHd8uEnkP9GeyfxBiCw6RD8Qsvic1JjKSkkjVXSXF58LZXDeuGocuX/MtWZrkwwCHyEdSLesgFhMZSWlsn6E4z9dgs0r0Yv225rydi0oFzoETrBjgEEkgO02HPYtG4d2ZGYhv631OgStMZCQly07TYe/i0Zivv92r98/+n2+Rs7kMe49f9CrY8GQuquY4B07wYoBDJJEItQojeifipQf7QwVpu6yYyEjhIEKtsi3t4OmEmnWNZnxeYcDUv5Yg/YUCj0dW+drFxa7j4MMAh0hi1ub2JB+a21vikgwUTrLTdNj91N1ez5VTe60Jczbvx2cHzrcaDeWMr12/7DoOPhxFRSSD7DQdOsREYupfS3zeFmcvpnBUduqy1yOrrOZt/c4uQTghNhITB90CfaoWw7on2H2mPB0RaWVd2Zxdx8GHLThEMrl4tUGS7XD2YgpHUnT5tGywqalrwvq9JzFl3b5WM4sDcDrXjTvsOg5ObMEhkomvTdb8ZUjhTO4unypjPeZs3o8nRveCqf4GPiw/77TFSKUCBAeRj04Tg2X3pbLrOEgxwCGSibdN3gCTiol8+fx44rXC427LCMLN7q3xA5Nxa8d2SGgfDW1cTKtuLgou7KIikomrSQCto6z+9NvBmK+/vdXQciYVU7hr/vkJBpfrmrDx61O4pWNbTBx8CzJ7dmJwE+RUguCo4U3ZTCYTNBoNjEYj4uLiAl0dUjhHU7+3bNo2WwSUVtbgwpV6dOnAX4ZEVvkVVVj8j4OovR74GYOt3cZ7Fo3i5zNAPPn+lq0F5w9/+APuvPNOtGvXDvHx8aLeIwgCli5dCp1Oh7Zt20Kv1+PYsWN2ZWpqajB16lTExcUhPj4eM2fOxNWrV2U4AiJpWCcB3DprOF6fPAhbZw3HnkWj7FpnItQqZPbshPGD+MuQqLnsNB3WTB0S6GoA4KR+oUa2AKexsRG/+c1vkJOTI/o9L7/8Mt544w2sXbsWJSUliI2NRVZWFurrf/7lO3XqVBw6dAgFBQX45JNP8NVXX2H27NlyHAKRZBjAEHlveI9O0Gli/Lbemzuc1C80yN5FtXHjRjzxxBOora11WU4QBCQnJ2PhwoV48sknAQBGoxFJSUnYuHEjJk+ejCNHjiA1NRXffPMNhg4dCgDIz8/H2LFjcfbsWSQnJ4uqE7uoiIhCi3UhTAB2SceqFv/2h62zhkuycjl5Lii6qDxVWVkJg8EAvV5ve06j0SAjIwPFxcUAgOLiYsTHx9uCGwDQ6/VQq9UoKXE+oVpDQwNMJpPdg4iIQoezRW21mhisfWgI1j40BAmx8qwDZ8X14EJL0AwTNxgMAICkpCS755OSkmyvGQwGdOnSxe71Nm3aICEhwVbGkby8PDz33HMS15iIiPwpO02He1K1ThPyrzdZMP/9cln2zakbQo9HLTiLFy+GSqVy+fjhhx/kqqvXcnNzYTQabY8zZ84EukpEROQFV/ls2jjfJgdMiI3EzBHdMF9/e6ttceqG0ONRC87ChQsxffp0l2V69OjhVUW0Wi0AoLq6GjrdzxdQdXU1Bg0aZCtz4cIFu/fduHEDNTU1tvc7Eh0djeho6RY+JCKi4OPp5ICPj+6FYd074eLVhlatQfNG9eLUDSHOowCnc+fO6Ny5sywV6d69O7RaLQoLC20BjclkQklJiW0kVmZmJmpra1FWVob09HQAQFFRESwWCzIyMmSpFxERhQbr5IA5m/e7TD4Ws8SCtaWIQpdsOTinT59GTU0NTp8+DbPZjPLycgBAr1690L59ewBA3759kZeXh4kTJ0KlUuGJJ57ACy+8gN69e6N79+5YsmQJkpOTMWHCBABAv379kJ2djVmzZmHt2rVoamrCvHnzMHnyZNEjqIiISLmsycgtJ9d0tZI4KZNsAc7SpUuxadMm278HDx4MAPjyyy9x1113AQCOHj0Ko9FoK/P000+jrq4Os2fPRm1tLUaOHIn8/HzExPzcF/ruu+9i3rx5GD16NNRqNR588EG88cYbch0GERGFGHfJyBQeuFQD58EhIiIKCSE5Dw4RERGRVBjgEBERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIcWRbqiGYWSdvNplMAa4JERERiWX93hazCENYBjhXrlwBAKSkpAS4JkREROSpK1euQKPRuCwTlmtRWSwWnD9/Hh06dIBKJe3iayaTCSkpKThz5gzXuXKD50o8nivP8HyJx3PlGZ4v8eQ4V4Ig4MqVK0hOToZa7TrLJixbcNRqNW699VZZ9xEXF8eLXySeK/F4rjzD8yUez5VneL7Ek/pcuWu5sWKSMRERESkOAxwiIiJSHAY4EouOjsayZcsQHR0d6KoEPZ4r8XiuPMPzJR7PlWd4vsQL9LkKyyRjIiIiUja24BAREZHiMMAhIiIixWGAQ0RERIrDAIeIiIgUhwGOhNasWYNu3bohJiYGGRkZKC0tDXSVAm758uVQqVR2j759+9per6+vx9y5c9GpUye0b98eDz74IKqrqwNYY//66quvcN999yE5ORkqlQoffvih3euCIGDp0qXQ6XRo27Yt9Ho9jh07ZlempqYGU6dORVxcHOLj4zFz5kxcvXrVj0fhH+7O1fTp01tda9nZ2XZlwuVc5eXl4Y477kCHDh3QpUsXTJgwAUePHrUrI+azd/r0aYwbNw7t2rVDly5d8NRTT+HGjRv+PBS/EHO+7rrrrlbX15w5c+zKhMP5euuttzBgwADb5H2ZmZn4/PPPba8H03XFAEci77//PhYsWIBly5Zh//79GDhwILKysnDhwoVAVy3gfvGLX6Cqqsr22LNnj+21+fPnY8eOHdi2bRt2796N8+fP44EHHghgbf2rrq4OAwcOxJo1axy+/vLLL+ONN97A2rVrUVJSgtjYWGRlZaG+vt5WZurUqTh06BAKCgrwySef4KuvvsLs2bP9dQh+4+5cAUB2drbdtbZ161a718PlXO3evRtz587Fvn37UFBQgKamJowZMwZ1dXW2Mu4+e2azGePGjUNjYyO+/vprbNq0CRs3bsTSpUsDcUiyEnO+AGDWrFl219fLL79sey1cztett96Kl156CWVlZfj2228xatQojB8/HocOHQIQZNeVQJIYNmyYMHfuXNu/zWazkJycLOTl5QWwVoG3bNkyYeDAgQ5fq62tFSIjI4Vt27bZnjty5IgAQCguLvZTDYMHAGH79u22f1ssFkGr1QqrVq2yPVdbWytER0cLW7duFQRBEA4fPiwAEL755htbmc8//1xQqVTCuXPn/FZ3f2t5rgRBEB5++GFh/PjxTt8TrudKEAThwoULAgBh9+7dgiCI++x99tlnglqtFgwGg63MW2+9JcTFxQkNDQ3+PQA/a3m+BEEQfv3rXwuPP/640/eE8/nq2LGj8Ne//jXoriu24EigsbERZWVl0Ov1tufUajX0ej2Ki4sDWLPgcOzYMSQnJ6NHjx6YOnUqTp8+DQAoKytDU1OT3Xnr27cvbrvtNp43AJWVlTAYDHbnR6PRICMjw3Z+iouLER8fj6FDh9rK6PV6qNVqlJSU+L3OgbZr1y506dIFffr0QU5ODi5dumR7LZzPldFoBAAkJCQAEPfZKy4uRv/+/ZGUlGQrk5WVBZPJZPu1rlQtz5fVu+++i8TERKSlpSE3NxfXrl2zvRaO58tsNuO9995DXV0dMjMzg+66CsvFNqV28eJFmM1muz8YACQlJeGHH34IUK2CQ0ZGBjZu3Ig+ffqgqqoKzz33HH75y1+ioqICBoMBUVFRiI+Pt3tPUlISDAZDYCocRKznwNF1ZX3NYDCgS5cudq+3adMGCQkJYXcOs7Oz8cADD6B79+44ceIEnnnmGdx7770oLi5GRERE2J4ri8WCJ554AiNGjEBaWhoAiPrsGQwGh9ee9TWlcnS+AOC3v/0tunbtiuTkZBw4cACLFi3C0aNH8cEHHwAIr/N18OBBZGZmor6+Hu3bt8f27duRmpqK8vLyoLquGOCQrO69917b/w8YMAAZGRno2rUr/va3v6Ft27YBrBkpzeTJk23/379/fwwYMAA9e/bErl27MHr06ADWLLDmzp2LiooKu9w3cs7Z+Wqeq9W/f3/odDqMHj0aJ06cQM+ePf1dzYDq06cPysvLYTQa8fe//x0PP/wwdu/eHehqtcIuKgkkJiYiIiKiVaZ4dXU1tFptgGoVnOLj43H77bfj+PHj0Gq1aGxsRG1trV0ZnrebrOfA1XWl1WpbJbLfuHEDNTU1YX8Oe/TogcTERBw/fhxAeJ6refPm4ZNPPsGXX36JW2+91fa8mM+eVqt1eO1ZX1MiZ+fLkYyMDACwu77C5XxFRUWhV69eSE9PR15eHgYOHIjXX3896K4rBjgSiIqKQnp6OgoLC23PWSwWFBYWIjMzM4A1Cz5Xr17FiRMnoNPpkJ6ejsjISLvzdvToUZw+fZrnDUD37t2h1Wrtzo/JZEJJSYnt/GRmZqK2thZlZWW2MkVFRbBYLLYbcLg6e/YsLl26BJ1OByC8zpUgCJg3bx62b9+OoqIidO/e3e51MZ+9zMxMHDx40C4oLCgoQFxcHFJTU/1zIH7i7nw5Ul5eDgB211e4nK+WLBYLGhoagu+6kjRlOYy99957QnR0tLBx40bh8OHDwuzZs4X4+Hi7TPFwtHDhQmHXrl1CZWWlsHfvXkGv1wuJiYnChQsXBEEQhDlz5gi33XabUFRUJHz77bdCZmamkJmZGeBa+8+VK1eE7777Tvjuu+8EAMIrr7wifPfdd8KpU6cEQRCEl156SYiPjxc++ugj4cCBA8L48eOF7t27C9evX7dtIzs7Wxg8eLBQUlIi7NmzR+jdu7cwZcqUQB2SbFydqytXrghPPvmkUFxcLFRWVgo7d+4UhgwZIvTu3Vuor6+3bSNczlVOTo6g0WiEXbt2CVVVVbbHtWvXbGXcffZu3LghpKWlCWPGjBHKy8uF/Px8oXPnzkJubm4gDklW7s7X8ePHheeff1749ttvhcrKSuGjjz4SevToIfzqV7+ybSNcztfixYuF3bt3C5WVlcKBAweExYsXCyqVSvjiiy8EQQiu64oBjoTefPNN4bbbbhOioqKEYcOGCfv27Qt0lQJu0qRJgk6nE6KiooRbbrlFmDRpknD8+HHb69evXxceffRRoWPHjkK7du2EiRMnClVVVQGssX99+eWXAoBWj4cfflgQhJtDxZcsWSIkJSUJ0dHRwujRo4WjR4/abePSpUvClClThPbt2wtxcXHCjBkzhCtXrgTgaOTl6lxdu3ZNGDNmjNC5c2chMjJS6Nq1qzBr1qxWPzDC5Vw5Ok8AhLfffttWRsxn7+TJk8K9994rtG3bVkhMTBQWLlwoNDU1+flo5OfufJ0+fVr41a9+JSQkJAjR0dFCr169hKeeekowGo122wmH8/W73/1O6Nq1qxAVFSV07txZGD16tC24EYTguq5UgiAI0rYJEREREQUWc3CIiIhIcRjgEBERkeIwwCEiIiLFYYBDREREisMAh4iIiBSHAQ4REREpDgMcIiIiUhwGOERERKQ4DHCIiIhIcRjgEBERkeIwwCEiIiLFYYBDREREivP/AdYXNQkQq4WcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(300)), -test_data[7, 0, :].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'globalstar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data_config.labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(test_data[0] == -1) / 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4189750692514971, 0.19999266221423792)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(t.val_set.data[0]), np.std(t.val_set.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3947, device='cuda:0', dtype=torch.float64),\n",
       " tensor(0.2815, device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(test_data[0][test_data[0] != -1]), torch.std(test_data[0][test_data[0] != -1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5c718b550bc3d753c2633a9373069f979ac103108d12860e85b5c2009111e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

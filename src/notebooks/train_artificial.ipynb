{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "def get_new_net(cfg):\n",
    "    seed = np.random.randint(1000000)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test train on synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all:  20%|██        | 1/5 [00:01<00:04,  1.20s/it]c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\data\\data_load.py:22: RuntimeWarning: divide by zero encountered in log10\n",
      "  arr = -2.5 * np.log10(arr)\n",
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "(1800, 300)\n",
      "label: atlasv -> 1620 training examples, 180 testing examples\n",
      "label: cz3 -> 1173 training examples, 130 testing examples\n",
      "label: falcon9 -> 1152 training examples, 128 testing examples\n",
      "label: globalstar -> 955 training examples, 106 testing examples\n",
      "label: h2a -> 1289 training examples, 143 testing examples\n",
      "Training set: 50000\n",
      "Validation set: 50000\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(net, sampler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [01:54<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(100, print_on=False, save_interval=20, tensorboard_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 atlasv\n",
      "1 cz3\n",
      "2 falcon9\n",
      "3 globalstar\n",
      "4 h2a\n",
      "Train:\n",
      "\tLoss: 0.00023927600113650866\n",
      "\tAcc: 97.616\n",
      "Validation:\n",
      "\tLoss: 0.0004295219167308759\n",
      "\tAcc: 96.654\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  atlasv   cz3  falcon9  globalstar   h2a\n",
      "0      atlasv    9441   559        0           0     0\n",
      "1         cz3       1  9634      342          23     0\n",
      "2     falcon9       0    46     9919           6    29\n",
      "3  globalstar       0    48        0        9870    82\n",
      "4         h2a       0    82      110         345  9463\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              atlasv        cz3    falcon9  globalstar       h2a\n",
      "Precision  94.410000  96.340000  99.190000   98.700000  94.63000\n",
      "Recall     99.989409  92.911563  95.641693   96.349082  98.84061\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/6classes\"\n",
    "trainer.load_data_from_file(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_set.data = trainer.train_set.data[trainer.train_set.labels != 1]\n",
    "trainer.train_set.labels = trainer.train_set.labels[trainer.train_set.labels != 1]\n",
    "trainer.train_set.labels[trainer.train_set.labels != 0] = trainer.train_set.labels[trainer.train_set.labels != 0] - 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/Fall_2021_2: 100%|██████████| 495/495 [00:01<00:00, 433.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9134, 300)\n",
      "(20844, 300)\n",
      "(1907, 300)\n",
      "(27295, 300)\n",
      "(2478, 300)\n"
     ]
    }
   ],
   "source": [
    "from data.data_load import load_data\n",
    "from data.filters import filter_data\n",
    "\n",
    "real_labels = [\"falcon_9\",\n",
    "          \"atlas_5\",\n",
    "          \"h-2a\",\n",
    "          \"globalstar\",\n",
    "          \"cz-3\"\n",
    "]\n",
    "labled_data = load_data(PACKAGE_PATH + \"/resources/Fall_2021_2\", labels=real_labels, convert_to_mag=False)\n",
    "\n",
    "filtered_data = filter_data(labled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "for key in filtered_data:\n",
    "    new_data[key.replace(\"_\", \"\").replace(\"-\", \"\").replace(\"5\", \"v\")] = filtered_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['atlasv', 'cz3', 'falcon9', 'globalstar', 'h2a']),\n",
       " ['atlasv', 'cz3', 'falcon9', 'globalstar', 'h2a'],\n",
       " dict_keys(['atlas_5', 'cz-3', 'falcon_9', 'globalstar', 'h-2a']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.keys(), LABELS, filtered_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_set = train_set\n",
    "# trainer.val_set = val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on real data with 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"RTRT_v2_sampler\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "cfg.data_config.validation_split = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt: 100%|██████████| 5/5 [00:00<00:00, 35.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 17080 examples.\n",
      "Label: cz_3 39000 examples.\n",
      "Label: falcon_9 5655 examples.\n",
      "Label: globalstar 42172 examples.\n",
      "Label: h2a 5860 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.516  0.9578 1.516  ... 1.516  0.9578 3.813 ]\n",
      "[1.516  0.243  3.813  ... 0.9578 0.9578 3.813 ]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "trainer = Trainer(net)\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [01:21<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(101, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.0032061392752120027\n",
      "\tAcc: 84.816\n",
      "Validation:\n",
      "\tLoss: 0.015361303875833005\n",
      "\tAcc: 48.088\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5   h2a  globalstar\n",
      "0        cz_3  1514      1966      401   998         121\n",
      "1    falcon_9   970      2592      446   876         116\n",
      "2     atlas_5   594       520     2472   768         646\n",
      "3         h2a   774       998      546  2518         164\n",
      "4  globalstar   611       264      815   384        2926\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "               cz_3   falcon_9    atlas_5       h2a  globalstar\n",
      "Precision  30.28000  51.840000  49.440000  50.36000   58.520000\n",
      "Recall     33.92337  40.883281  52.820513  45.41847   73.647118\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on real using augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 898468 \n",
      "\n",
      "cuda:0\n",
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all:  20%|██        | 1/5 [00:01<00:04,  1.02s/it]c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\data\\data_load.py:22: RuntimeWarning: divide by zero encountered in log10\n",
      "  arr = -2.5 * np.log10(arr)\n",
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/../artificial_data/data/all: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: atlasv -> 1620 training examples, 180 testing examples\n",
      "label: cz3 -> 1620 training examples, 180 testing examples\n",
      "label: falcon9 -> 1620 training examples, 180 testing examples\n",
      "label: globalstar -> 1620 training examples, 180 testing examples\n",
      "label: h2a -> 1620 training examples, 180 testing examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyselica\\Desktop\\kyselica\\classification_of_light_curves\\src\\notebooks\\..\\nn\\dataset.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  d[d!=-1] = (d[d!=-1] - min_value[i]) / diff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000\n",
      "Validation set: 50000\n",
      "50000\n",
      "58111\n"
     ]
    }
   ],
   "source": [
    "net, seed = get_new_net()\n",
    "trainer = Trainer(net, sampler=False)\n",
    "DATA_PATH = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/6classes\"\n",
    "print(len(trainer.train_set))\n",
    "trainer.load_data_from_file(DATA_PATH)\n",
    "print(len(trainer.train_set))\n",
    "remove_titan_class(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55736\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.dataset import create_datasets, AugmentedBalancedDataset, NetDataset\n",
    "\n",
    "dataset_args = {\n",
    "    \"max_noise\": 0.05, \n",
    "    \"num_gaps\": 2, \"min_gap_len\": 5,\n",
    "    \"max_gap_len\": 10, \n",
    "    \"gap_prob\": 0.01, \n",
    "    \"use_original_data\": True, \n",
    "    \"min_num_examples\": 10000\n",
    "}\n",
    "\n",
    "# train_set, val_set = create_datasets(new_data, LABELS, validation_split=0.1, output_folder=None, \n",
    "#                                 dataset_class=NetDataset, aditional_dataset_args={})\n",
    "\n",
    "train_set = AugmentedBalancedDataset(trainer.train_set.data, trainer.train_set.labels, **dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train_set = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 301/301 [05:44<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 atlasv\n",
      "1 cz3\n",
      "2 falcon9\n",
      "3 globalstar\n",
      "4 h2a\n",
      "Train:\n",
      "\tLoss: 0.002063445328441889\n",
      "\tAcc: 90.4765322233386\n",
      "Validation:\n",
      "\tLoss: 0.0027077191074343283\n",
      "\tAcc: 88.4329563812601\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  atlasv  cz3  falcon9  globalstar   h2a\n",
      "0      atlasv    1990   16       39          35    39\n",
      "1         cz3     116   64        6           7     4\n",
      "2     falcon9     162    8      649          16    54\n",
      "3  globalstar      44    4        5         185    14\n",
      "4         h2a      61   10       47          29  2586\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              atlasv        cz3    falcon9  globalstar        h2a\n",
      "Precision  93.912223  32.487310  73.003375   73.412698  94.621295\n",
      "Recall     83.860093  62.745098  86.997319   68.014706  95.884316\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(301, print_on=False, save_interval=100, tensorboard_on=True)\n",
    "trainer.evaluate(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv1d(1, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): MaxPool1d(kernel_size=5, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (7): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=592, out_features=128, bias=True)\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "def get_new_net(cfg):\n",
    "    seed = np.random.randint(1000000)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"TSTS_obs_15_75_v1\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "augmentation_cfg = AugmentationConfig(\n",
    "    min_examples = 5000,\n",
    "    roll=True,\n",
    "    add_gaps=True,\n",
    "    add_noise=True,\n",
    "    max_noise=.03,\n",
    "    keep_original=False,\n",
    "    num_gaps = 2,\n",
    "    gap_prob = .2,\n",
    "    min_gap_len = 5,\n",
    "    max_gap_len = 15\n",
    ")\n",
    "cfg.data_config.augmentation = augmentation_cfg\n",
    "# cfg.data_config.filter = FilterConfig()\n",
    "# cfg.data_config.filter.n_bins = 30\n",
    "# cfg.data_config.filter.n_gaps = 2\n",
    "# cfg.data_config.filter.gap_size = 2\n",
    "# cfg.data_config.filter.rms_ratio = .0\n",
    "# cfg.data_config.filter.non_zero_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = net.load(checkpoint=8)\n",
    "# cfg.seed = seed\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# random.seed(seed)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(net, sampler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 557.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[2492. 2515.  126. 1743. 1761. 1611. 1065.  126. 2241.  274.  798.  887.\n",
      "  128. 1484. 3751.  925. 1092. 1826. 2966.  973. 2433.  913.  443. 1549.\n",
      " 1655.  126. 3599. 1624.  127. 2038.  872. 1917. 1586. 1702. 2182. 3527.\n",
      " 2288.  117. 1626. 1108.  654. 1279.  701. 1532.  494. 1549. 2484. 1022.\n",
      " 1606. 1355.  798. 2460. 1077.  122.  127. 2388. 1976. 1761. 1828. 1973.\n",
      " 1279. 2088.  817. 1681.  123.  808. 1590. 3253. 3757.  122. 1299.  768.\n",
      "  972.  554.  768.  141. 2785. 1735. 2531. 2633. 1954. 1399.  847.  910.\n",
      " 2286. 3599.  554.  554. 1253. 2222. 1167. 1550.  942. 2222. 1105. 3253.\n",
      "  654. 2484. 1270. 3631.  816. 1549. 2204. 1043.  123. 2288.  847.  764.\n",
      " 1962. 2515. 2112.  591. 2564.  203.  872. 1761. 1244. 2038.  190. 2100.\n",
      "  203.  349. 1681. 1613.  271. 1285.  910. 1164.  494. 1279.  710. 1108.\n",
      " 2038.  299. 2438. 2663. 1180. 1377.  122. 2288. 2038. 1249. 1463.  905.\n",
      " 1231. 2978. 2088.  740. 3820. 2809. 1152.  992. 2663. 3397. 3751. 1876.\n",
      " 3397. 1485. 1611.  124.  899.  127. 1077. 2492. 3788. 1097. 1012. 1820.\n",
      " 1976. 1167. 1954.  992.  899.  177. 2343. 1462. 2388. 2852. 3437. 2343.\n",
      " 1876. 2027. 1976. 1164. 2100. 1247. 1956. 2397.  203. 2251.  122. 1048.\n",
      " 3788. 1079.  200. 1815. 1312. 2189. 1008. 1202.  773. 3159. 2343. 1877.\n",
      " 1230. 3367.  306.  303.  117. 2288. 3064. 2038. 2982.  239.  772. 1928.\n",
      " 1159. 1152. 2088. 3754. 1012. 3820.  127. 1108. 1529.  122. 2360.  640.\n",
      "  127. 2359. 1079. 1167.  750. 1231. 1108. 2507. 2131. 1876. 1231.  121.\n",
      " 2758. 3631. 2198. 1913. 1377.  817.  190. 2288. 1917. 1701. 2564. 1877.\n",
      " 1042. 1911.  117. 2251. 1761. 1043. 3673. 1112. 1092.  764.  722. 3631.\n",
      " 1976. 2088. 1299. 3788. 2241.  640.  817. 1065.  126.  239.  913. 2112.\n",
      " 1973.  126. 1928. 3767.  972. 2170. 1016. 1250.  899. 2460. 3599. 2189.\n",
      " 2251. 1885. 2185.  965. 1761. 1816.  830. 1231. 2614. 1839. 1112. 2531.\n",
      "  177. 1230. 1976. 1315. 1079. 2151. 3202. 1655. 1550.  122.  126.  745.\n",
      "  125. 3064.  992.  768. 1785.  972. 3476. 2484. 2385. 2395. 1741. 2027.\n",
      " 1250. 1758.  750. 2457. 2286. 2189. 1026. 1606. 2158. 3159. 1696. 1312.\n",
      " 1820. 1702. 2088. 2454. 2433. 1973. 1876. 2360. 2131. 2288.  127.  135.\n",
      "  740.  591. 3673. 1876.  190. 2127. 2343. 2397.  972. 1159.  740. 1463.\n",
      " 1270. 1159.  120.  872. 1167. 1396. 1105. 3788.  160.  847. 1641. 2073.\n",
      "  126. 3754. 1484. 1611. 1917. 3751. 2344. 1484. 2560. 2111. 1797. 2982.\n",
      " 2038. 2852.  494. 2560. 1065. 2388. 1928. 1065. 2680.  772.  133. 2286.\n",
      " 1862. 1249.  942. 1159. 1917. 1633. 2027. 1613. 3317. 2200. 3711. 1876.\n",
      " 1355. 1917. 2438. 1108. 1108.  177. 1816. 2288. 1840.  740. 1396. 1043.\n",
      " 2462. 1212. 2852. 1550. 2251. 2460. 1550. 1816. 1315. 2073. 2101. 2454.\n",
      "  604.  144.  126. 1956.  847. 1972. 1112.  899. 1146.  127. 1167.  740.\n",
      " 1911. 1758.  190. 1281. 1250. 1244. 3317. 1876.  123. 1097.  203.  554.\n",
      " 1761. 1830. 1354. 1696.  973.  274. 2484.  942. 1885. 1299.  847.  772.\n",
      " 1270. 1012. 2608. 1202. 1458.  836. 1865. 1008.  839. 1355.  790. 3599.\n",
      " 1202.  973.  133. 1016.  847.  648. 1798.  117. 2091.  126. 2159. 2560.\n",
      "  184. 2292. 1681.  120. 2809. 1390. 1250.  394. 1911.  303. 3317. 2131.\n",
      " 1840. 2388.  127. 1696.  271. 2038. 1270. 1549. 1008. 3001. 1613. 1186.\n",
      "  795. 1250. 2078. 1202. 1285. 2388. 1225. 2809.  203. 2701. 1733.  817.\n",
      " 1529. 2005.  992. 1108.  160. 1743.  942. 1815. 1613. 1976.  740. 1520.\n",
      "  992. 1701.  996. 1743.  120. 1819.  604. 1741.  160. 1377. 1105. 1536.\n",
      "  349. 2564. 1164. 2343. 1016. 1377. 1164.  972. 1047.  160.  547.  942.\n",
      "  202. 1065. 1399. 1007.  913. 2388. 1761. 3713. 2921.  992. 1279.  490.\n",
      " 1354.  125. 2564.  396.]\n",
      "[ 868.  793.  153. ... 1815.  883.  469.]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "cfg.data_config.validation_split = 0.1\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 301/301 [04:02<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(301, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.000891152670759398\n",
      "\tAcc: 95.98\n",
      "Validation:\n",
      "\tLoss: 0.011142647005266251\n",
      "\tAcc: 77.892\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5   h2a  globalstar\n",
      "0        cz_3  3319       274       53  1354           0\n",
      "1    falcon_9  1583      2630       82   705           0\n",
      "2     atlas_5   283        39     4494   184           0\n",
      "3         h2a   602       168      198  4030           2\n",
      "4  globalstar     0         0        0     0        5000\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz_3   falcon_9    atlas_5        h2a  globalstar\n",
      "Precision  66.380000  52.600000  89.880000  80.600000  100.000000\n",
      "Recall     57.352687  84.538734  93.101305  64.243584   99.960016\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test real trained network on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"RTRT_v1_687129\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "augmentation_cfg = AugmentationConfig(\n",
    "    min_examples = 5000,\n",
    "    roll=True,\n",
    "    add_gaps=True,\n",
    "    add_noise=True,\n",
    "    max_noise=.03,\n",
    "    keep_original=False,\n",
    "    num_gaps = 2,\n",
    "    gap_prob = .2,\n",
    "    min_gap_len = 5,\n",
    "    max_gap_len = 15\n",
    ")\n",
    "cfg.data_config.augmentation = augmentation_cfg\n",
    "cfg.data_config.validation_split = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 626.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[ 923. 1587. 1733. ... 1900. 1164. 2225.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.900e+01 4.380e+02 2.660e+02 2.000e+00 3.000e+00 1.217e+03 4.910e+02\n",
      " 1.255e+03 1.064e+03 4.440e+02 3.900e+02 2.000e+01 1.440e+03 7.900e+01\n",
      " 6.100e+02 3.000e+01 1.940e+02 1.550e+02 1.000e+00 1.400e+02 1.100e+01\n",
      " 1.000e+00 1.196e+03 7.020e+02 3.000e+00 2.392e+03 1.340e+02 8.900e+02\n",
      " 1.200e+02 1.959e+03 1.560e+02 1.830e+02 2.230e+02 6.400e+01 5.500e+01\n",
      " 1.000e+00 1.737e+03 9.500e+01 2.323e+03 7.100e+01 1.000e+00 1.360e+03\n",
      " 1.504e+03 1.442e+03 2.016e+03 9.510e+02 2.740e+02 5.000e+00 2.610e+02\n",
      " 2.500e+01 3.847e+03 9.640e+02 1.900e+02 3.460e+02 2.210e+02 1.692e+03\n",
      " 1.752e+03 3.600e+01 2.000e+00 9.000e+01 1.700e+01 1.702e+03 9.900e+01\n",
      " 1.826e+03 1.000e+00 1.000e+00 7.220e+02 1.200e+01 6.000e+02 1.000e+00\n",
      " 5.990e+02 2.741e+03 1.550e+02 3.182e+03 1.045e+03 5.580e+02 2.367e+03\n",
      " 2.000e+00 8.090e+02 1.949e+03 1.000e+00 2.400e+01 1.239e+03 2.388e+03\n",
      " 1.443e+03 2.000e+00 1.115e+03 5.100e+01 9.900e+01 1.000e+00 7.340e+02\n",
      " 9.060e+02 3.740e+02 5.220e+02 1.752e+03 1.000e+00 3.530e+02 2.900e+01\n",
      " 2.180e+02 1.000e+01 1.659e+03 2.112e+03 1.461e+03 1.181e+03 1.020e+03\n",
      " 1.188e+03 3.820e+02 2.579e+03 1.510e+02 8.350e+02 8.700e+01 1.309e+03\n",
      " 1.682e+03 3.000e+01 1.913e+03 1.470e+02 1.000e+00 1.060e+02 2.000e+01\n",
      " 1.570e+02 1.689e+03 6.870e+02 6.100e+01 1.000e+00 1.356e+03 2.000e+00\n",
      " 1.210e+02 1.663e+03 2.000e+00 9.800e+01 2.378e+03 2.920e+02 2.144e+03\n",
      " 1.000e+00 1.242e+03 3.000e+00 2.390e+02 1.270e+02 1.800e+02 1.565e+03\n",
      " 3.250e+02 9.400e+01 2.350e+02 5.000e+00 1.530e+02 5.820e+02 7.700e+02\n",
      " 2.285e+03 5.280e+02 1.590e+02 4.440e+02 2.300e+01 4.900e+01 3.910e+02\n",
      " 1.000e+00 4.770e+02 1.000e+00 2.735e+03 1.860e+02 9.900e+01 6.000e+02\n",
      " 4.000e+00 4.200e+02 3.300e+01 1.043e+03 1.000e+00 1.039e+03 3.770e+02\n",
      " 2.090e+02 6.850e+02 6.110e+02 3.700e+02 7.800e+01 3.073e+03 4.470e+02\n",
      " 2.760e+02 3.110e+02 1.778e+03 1.000e+00 2.994e+03 1.800e+01 4.440e+02\n",
      " 2.669e+03 9.000e+01 1.279e+03 8.160e+02 5.000e+00 1.280e+02 1.167e+03\n",
      " 3.800e+01 1.149e+03 1.000e+00 2.500e+01 2.000e+00 2.480e+02 7.800e+01\n",
      " 2.300e+01 9.600e+01 1.120e+02 1.629e+03 2.870e+02 7.000e+01 8.830e+02\n",
      " 1.939e+03 8.400e+01 1.000e+00 1.770e+02 3.000e+00 8.900e+02 1.452e+03\n",
      " 2.078e+03 1.476e+03 3.470e+02 6.900e+02 9.110e+02 1.532e+03 1.154e+03\n",
      " 3.000e+00 1.300e+01 1.802e+03 1.600e+01 3.120e+02 1.000e+00 1.704e+03\n",
      " 9.060e+02 4.950e+02 3.064e+03 9.100e+01 1.800e+01 1.700e+01 3.200e+01\n",
      " 1.103e+03 4.200e+02 1.220e+02 1.000e+00 1.833e+03 3.260e+02 4.940e+02\n",
      " 1.045e+03 2.000e+00 1.000e+00 2.020e+02 8.530e+02 7.060e+02 3.020e+02\n",
      " 1.000e+00 1.000e+00 1.000e+00 4.400e+02 4.290e+02 1.000e+00 2.800e+01\n",
      " 5.000e+00 1.289e+03 6.400e+02 5.000e+00 1.300e+01 3.910e+02 8.740e+02\n",
      " 7.230e+02 3.584e+03 1.360e+03 1.470e+02 4.790e+02 2.680e+03 4.100e+01\n",
      " 7.440e+02 1.023e+03 8.440e+02 3.640e+02 7.680e+02 6.110e+02 1.080e+02\n",
      " 2.041e+03 1.000e+00 6.800e+01 1.000e+00 1.331e+03 4.460e+02 8.300e+02\n",
      " 2.534e+03 5.870e+02 1.159e+03 1.209e+03 1.050e+02 2.530e+02 1.000e+00\n",
      " 9.900e+01 1.629e+03 3.500e+01 8.700e+01 1.004e+03 1.503e+03 6.700e+01\n",
      " 1.230e+02 1.000e+00 4.000e+00 4.100e+01 4.560e+02 1.528e+03 3.870e+02\n",
      " 5.200e+01 6.430e+02 2.140e+03 1.294e+03 1.186e+03 2.679e+03 2.350e+03\n",
      " 1.000e+00 2.590e+02 2.173e+03 2.980e+02 2.235e+03 1.369e+03 3.136e+03\n",
      " 1.000e+00 1.384e+03 6.240e+02 6.300e+01 1.000e+00 9.500e+02 2.348e+03\n",
      " 2.741e+03 3.850e+02 3.590e+02 2.060e+02 1.700e+01 1.453e+03 6.910e+02\n",
      " 1.292e+03 1.600e+01 1.439e+03 6.210e+02 3.701e+03 2.040e+02 1.500e+03\n",
      " 5.430e+02 1.159e+03 1.300e+03 1.000e+00 1.255e+03 3.184e+03 1.042e+03\n",
      " 5.580e+02 6.500e+01 1.063e+03 3.064e+03 6.420e+02 2.910e+02 2.000e+00\n",
      " 2.504e+03 2.000e+00 1.869e+03 2.000e+00 1.240e+02 1.000e+00 3.000e+01\n",
      " 2.190e+02 2.000e+01 3.066e+03 1.000e+00 8.400e+01 1.400e+01 1.316e+03\n",
      " 1.000e+00 1.167e+03 4.470e+02 1.330e+02 2.000e+00 6.450e+02 2.353e+03\n",
      " 1.942e+03 2.039e+03 9.960e+02 1.734e+03 2.136e+03 1.210e+02 3.640e+02\n",
      " 1.452e+03 2.000e+00 2.800e+01 1.138e+03 5.880e+02 1.480e+02 1.106e+03\n",
      " 1.417e+03 6.200e+01 7.520e+02 9.820e+02 4.200e+02 1.839e+03 1.000e+00\n",
      " 1.896e+03 2.200e+03 2.958e+03 1.000e+00 7.700e+02 7.200e+01 1.606e+03\n",
      " 2.100e+02 2.289e+03 6.320e+02 6.730e+02 2.361e+03 1.513e+03 1.000e+00\n",
      " 2.058e+03 9.000e+01 2.000e+00 9.510e+02 1.000e+00 1.072e+03 1.130e+03\n",
      " 3.000e+00 1.000e+00 2.930e+02 4.510e+02 1.066e+03 1.170e+02 8.600e+01\n",
      " 5.690e+02 4.920e+02 4.550e+02 2.190e+02 2.040e+02 1.000e+00 1.628e+03\n",
      " 3.159e+03 4.000e+00 5.830e+02 3.000e+00 1.866e+03 1.278e+03 7.000e+01\n",
      " 2.128e+03 2.000e+00 1.683e+03 1.140e+02 1.510e+02 6.860e+02 9.390e+02\n",
      " 2.000e+00 1.701e+03 1.000e+00 3.470e+02 1.866e+03 1.600e+02 1.000e+00\n",
      " 1.983e+03 2.000e+00 1.867e+03 3.360e+02 6.600e+01 2.000e+00 2.000e+01\n",
      " 1.600e+01 1.493e+03 9.470e+02 1.752e+03 2.080e+02 6.900e+01 1.250e+02\n",
      " 1.782e+03 1.000e+00 2.198e+03 3.151e+03 2.000e+00 1.785e+03 7.380e+02\n",
      " 5.520e+02 3.390e+02 2.070e+03 1.000e+00 7.860e+02 3.680e+02 4.900e+02\n",
      " 4.900e+02 1.412e+03 1.500e+02 9.100e+02 9.580e+02 1.000e+00 5.310e+02\n",
      " 1.170e+02 1.289e+03 7.400e+02 1.000e+00 2.100e+01 1.074e+03 2.740e+02\n",
      " 1.000e+00 1.956e+03 1.924e+03 1.046e+03 2.397e+03 3.530e+02 1.000e+00\n",
      " 1.000e+00 1.070e+03 1.369e+03 1.810e+02 1.608e+03 1.285e+03 5.190e+02\n",
      " 1.953e+03 4.510e+02 6.840e+02 2.160e+02 1.570e+02 5.580e+02 1.049e+03\n",
      " 5.900e+01 4.000e+00 1.252e+03 9.480e+02 1.522e+03 1.000e+00 1.343e+03\n",
      " 3.000e+00 6.210e+02 9.100e+01 1.040e+03 1.290e+02 1.168e+03 5.740e+02\n",
      " 1.169e+03 2.540e+02 1.272e+03 2.351e+03 4.000e+00 6.000e+00 1.866e+03\n",
      " 2.525e+03 1.544e+03 1.514e+03 2.674e+03 7.550e+02 1.621e+03 1.890e+02\n",
      " 1.570e+02 2.433e+03 1.730e+02 2.585e+03 1.699e+03 9.600e+01 1.726e+03\n",
      " 4.290e+02 1.255e+03 2.164e+03 6.480e+02 2.978e+03 6.410e+02 1.000e+00\n",
      " 2.600e+03 3.980e+02 2.080e+02 8.360e+02 1.190e+02 1.480e+02 1.700e+01\n",
      " 2.200e+03 1.077e+03 2.090e+02 1.684e+03 5.550e+02 8.300e+02 1.000e+00\n",
      " 9.060e+02 1.085e+03 9.000e+01 1.013e+03 9.880e+02 5.260e+02 1.586e+03\n",
      " 5.580e+02 7.350e+02 1.514e+03 1.000e+00 1.558e+03 4.270e+02]\n",
      "Training set: 25000\n",
      "Validation set: 25000\n"
     ]
    }
   ],
   "source": [
    "net = Net(cfg.net_config)\n",
    "net.load(checkpoint=10)\n",
    "trainer = Trainer(net)\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.3388745119816138\n",
      "\tAcc: 24.068\n",
      "Validation:\n",
      "\tLoss: 0.1888031129606694\n",
      "\tAcc: 22.156\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5  h2a  globalstar\n",
      "0        cz_3  3898       302      375  421           4\n",
      "1    falcon_9  3486       388      659  440          27\n",
      "2     atlas_5  3842       253      382  522           1\n",
      "3         h2a  3553       340      497  599          11\n",
      "4  globalstar  3736       109      303  580         272\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "              cz_3   falcon_9    atlas_5        h2a  globalstar\n",
      "Precision  77.9600   7.760000   7.640000  11.980000    5.440000\n",
      "Recall     21.0532  27.873563  17.238267  23.380172   86.349206\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADED BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train import Trainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.net import Net, ResNet\n",
    "from data.plot_light_curve import plot_curves\n",
    "\n",
    "from config import *\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from src.config import Config, DataConfig, FilterConfig, AugmentationConfig\n",
    "\n",
    "def get_new_net(cfg):\n",
    "    seed = np.random.randint(1000000)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    cfg.seed = seed\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cfg.net_config.name = f\"{cfg.net_config.name}_{seed}\"\n",
    "    # net = ResNet(net_cfg.n_classes, device=device, name=net_cfg.name)\n",
    "    net = Net(cfg.net_config)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"TRTR_8_11_2022\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/5class\"\n",
    "\n",
    "# cfg.data_config.filter = FilterConfig()\n",
    "# cfg.data_config.filter.n_bins = 30\n",
    "# cfg.data_config.filter.n_gaps = 2\n",
    "# cfg.data_config.filter.gap_size = 2\n",
    "# cfg.data_config.filter.rms_ratio = .0\n",
    "# cfg.data_config.filter.non_zero_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(net, sampler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt2: 100%|██████████| 5/5 [00:00<00:00, 100.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 2633 examples.\n",
      "Label: cz-3 9522 examples.\n",
      "Label: falcon_9 1953 examples.\n",
      "Label: globalstar 4152 examples.\n",
      "Label: h-2a 2187 examples.\n",
      "[3.497  3.497  3.497  ... 0.9578 0.902  0.9578]\n",
      "[0.9578     3.38108572 0.9578     ... 4.638      0.243      2.33978572]\n",
      "Training set: 18404\n",
      "Validation set: 2043\n"
     ]
    }
   ],
   "source": [
    "cfg.data_config.validation_split = 0.1\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 201/201 [01:18<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(201, 128,tensorboard_on=True, save_interval=50, print_on=False)\n",
    "net.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 2.9536910082116208e-05\n",
      "\tAcc: 99.96196479026298\n",
      "Validation:\n",
      "\tLoss: 0.004621698464046932\n",
      "\tAcc: 96.72050905531081\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3   937         4        6     4           1\n",
      "1    falcon_9     3       184        4     3           1\n",
      "2     atlas_5    14         1      246     1           1\n",
      "3        h-2a     5         1        1   205           6\n",
      "4  globalstar     2         2        4     3         404\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision  98.424370  94.358974  93.536122  94.036697   97.349398\n",
      "Recall     97.502601  95.833333  94.252874  94.907407   97.820823\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/synthetic/one_color/obs_15_75: 100%|██████████| 5/5 [00:00<00:00, 417.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 1160 examples.\n",
      "Label: cz_3 1160 examples.\n",
      "Label: falcon_9 1160 examples.\n",
      "Label: globalstar 1160 examples.\n",
      "Label: h2a 1160 examples.\n",
      "[3181.  680.  866. ...  994. 2070. 1252.]\n",
      "[1.492e+03 1.388e+03 5.580e+02 1.543e+03 1.606e+03 5.300e+01 2.500e+01\n",
      " 1.100e+02 1.000e+00 3.200e+02 1.760e+03 1.800e+01 1.115e+03 7.220e+02\n",
      " 9.500e+01 2.000e+00 9.190e+02 1.000e+00 1.335e+03 2.982e+03 3.010e+02\n",
      " 1.324e+03 1.597e+03 1.000e+00 6.300e+01 5.300e+01 1.000e+00 8.960e+02\n",
      " 1.922e+03 1.000e+00 2.000e+00 1.152e+03 1.340e+02 8.500e+01 1.000e+00\n",
      " 7.260e+02 4.000e+00 3.400e+02 1.962e+03 8.390e+02 3.200e+01 3.000e+00\n",
      " 3.617e+03 1.779e+03 3.000e+00 4.800e+01 5.090e+02 1.000e+00 4.610e+02\n",
      " 1.000e+00 7.060e+02 1.322e+03 1.720e+02 3.230e+02 1.000e+00 1.417e+03\n",
      " 7.100e+01 1.121e+03 3.760e+02 7.100e+01 1.366e+03 3.000e+02 3.661e+03\n",
      " 2.220e+02 6.000e+00 2.058e+03 2.000e+00 4.140e+02 2.011e+03 1.300e+02\n",
      " 1.910e+02 3.930e+02 4.330e+02 1.720e+02 2.860e+02 1.220e+02 2.000e+00\n",
      " 5.910e+02 2.000e+01 9.660e+02 6.400e+01 1.316e+03 1.000e+00 1.285e+03\n",
      " 1.806e+03 6.250e+02 6.420e+02 7.820e+02 1.900e+02 1.223e+03 1.692e+03\n",
      " 3.110e+02 1.000e+00 1.836e+03 3.000e+00 1.410e+02 6.180e+02 5.370e+02\n",
      " 1.794e+03 5.000e+00 1.900e+01 3.000e+00 5.000e+00 5.100e+02 4.000e+00\n",
      " 5.410e+02 5.000e+00 1.647e+03 2.750e+02 8.100e+01 3.000e+00 6.900e+01\n",
      " 1.410e+02 1.000e+00 1.630e+02 2.190e+02 8.500e+02 9.000e+00 3.630e+02\n",
      " 1.127e+03 1.310e+02 2.860e+02 3.760e+02 1.000e+00 1.460e+03 1.780e+02\n",
      " 8.870e+02 1.000e+00 4.950e+02 1.680e+03 5.410e+02 1.435e+03 3.480e+02\n",
      " 1.298e+03 5.390e+02 6.590e+02 5.810e+02 2.000e+00 1.760e+03 1.000e+00\n",
      " 4.000e+01 9.690e+02 1.700e+01 2.570e+02 8.700e+01 1.319e+03 1.483e+03\n",
      " 4.100e+01 2.350e+02 3.600e+01 3.100e+01 1.617e+03 1.430e+02 2.258e+03\n",
      " 1.270e+02 2.108e+03 5.630e+02 8.230e+02 5.700e+02 2.700e+01 1.260e+02\n",
      " 2.131e+03 3.340e+02 2.098e+03 3.100e+01 9.300e+01 3.518e+03 1.366e+03\n",
      " 4.580e+02 2.460e+02 1.120e+03 9.060e+02 7.240e+02 2.360e+02 1.600e+01\n",
      " 4.860e+02 6.700e+01 5.640e+02 1.290e+02 9.820e+02 9.800e+01 1.000e+00\n",
      " 9.900e+01 1.200e+02 1.000e+00 1.521e+03 2.500e+01 9.970e+02 1.700e+02\n",
      " 1.629e+03 9.900e+02 3.960e+02 1.000e+00 1.890e+02 1.200e+03 3.570e+02\n",
      " 2.000e+00 1.753e+03 2.468e+03 4.480e+02 1.968e+03 1.020e+03 6.110e+02\n",
      " 9.140e+02 1.600e+01 2.000e+00 2.738e+03 5.120e+02 5.850e+02 3.940e+02\n",
      " 2.289e+03 1.500e+01 7.350e+02 2.002e+03 1.498e+03 1.003e+03 5.260e+02\n",
      " 2.630e+02 5.880e+02 3.500e+02 1.741e+03 3.890e+02 5.000e+00 1.108e+03\n",
      " 1.865e+03 1.000e+00 2.000e+00 1.180e+02 1.258e+03 1.380e+02 2.670e+03\n",
      " 1.010e+03 9.650e+02 5.760e+02 2.133e+03 2.148e+03 1.000e+00 1.316e+03\n",
      " 1.000e+01 1.000e+00 1.510e+02 6.530e+02 4.100e+01 6.440e+02 9.700e+01\n",
      " 2.000e+00 6.900e+01 1.084e+03 2.480e+02 2.060e+02 2.289e+03 2.292e+03\n",
      " 1.240e+02 1.000e+00 6.000e+01 9.200e+01 4.910e+02 2.200e+02 1.420e+02\n",
      " 7.300e+01 6.670e+02 6.330e+02 1.868e+03 2.060e+03 1.407e+03 1.000e+00\n",
      " 6.580e+02 4.000e+00 1.160e+02 2.273e+03 2.000e+00 1.000e+00 3.360e+02\n",
      " 1.227e+03 3.900e+01 1.240e+02 1.097e+03 1.000e+00 2.780e+02 1.000e+00\n",
      " 8.670e+02 1.080e+02 2.390e+02 6.400e+01 1.000e+00 8.000e+00 7.590e+02\n",
      " 1.166e+03 3.110e+02 2.300e+02 1.410e+02 2.811e+03 6.300e+01 9.730e+02\n",
      " 1.912e+03 1.710e+03 2.136e+03 5.160e+02 3.000e+00 3.380e+02 1.487e+03\n",
      " 1.108e+03 1.810e+02 1.000e+00 9.000e+00 1.095e+03 1.830e+02 2.479e+03\n",
      " 3.321e+03 1.150e+02 1.083e+03 9.400e+01 1.000e+00 1.600e+01 1.273e+03\n",
      " 1.110e+02 5.500e+02 6.270e+02 1.900e+01 4.000e+00 1.366e+03 2.292e+03\n",
      " 1.726e+03 4.950e+02 6.830e+02 1.943e+03 2.000e+02 3.920e+02 1.800e+01\n",
      " 1.000e+00 1.000e+00 3.090e+02 1.550e+02 1.658e+03 1.472e+03 1.637e+03\n",
      " 1.322e+03 1.000e+00 2.407e+03 1.658e+03 2.480e+02 4.090e+02 1.000e+00\n",
      " 2.789e+03 1.000e+00 1.640e+02 1.000e+00 3.530e+02 2.000e+00 2.918e+03\n",
      " 4.820e+02 1.138e+03 1.087e+03 2.060e+02 6.500e+01 2.700e+02 1.000e+00\n",
      " 5.440e+02 1.000e+00 3.710e+02 8.000e+00 7.720e+02 2.550e+02 7.700e+02\n",
      " 8.670e+02 1.000e+02 8.400e+01 1.554e+03 1.000e+00 1.748e+03 1.720e+02\n",
      " 8.290e+02 1.940e+02 1.166e+03 8.700e+01 8.440e+02 4.470e+02 1.438e+03\n",
      " 2.000e+00 1.000e+00 1.000e+00 8.450e+02 1.550e+02 6.200e+01 1.200e+01\n",
      " 1.022e+03 1.773e+03 6.360e+02 9.760e+02 7.000e+00 2.510e+02 3.100e+01\n",
      " 1.036e+03 1.700e+02 1.815e+03 9.190e+02 1.040e+02 4.850e+02 5.000e+00\n",
      " 4.510e+02 1.662e+03 9.040e+02 2.930e+02 7.900e+01 7.340e+02 1.000e+00\n",
      " 2.000e+00 1.219e+03 2.343e+03 1.722e+03 1.163e+03 1.865e+03 1.127e+03\n",
      " 2.300e+01 5.540e+02 2.700e+01 7.180e+02 1.500e+01 1.314e+03 8.420e+02\n",
      " 4.050e+02 6.540e+02 1.158e+03 3.890e+02 5.500e+02 1.000e+00 1.000e+00\n",
      " 2.107e+03 1.400e+01 5.820e+02 7.100e+01 2.510e+02 6.080e+02 2.360e+03\n",
      " 3.260e+02 2.470e+02 2.000e+00 4.280e+02 1.870e+02 1.413e+03 9.800e+01\n",
      " 8.740e+02 1.322e+03 3.000e+00 6.070e+02 1.980e+02 5.690e+02 7.950e+02\n",
      " 1.234e+03 1.800e+01 3.560e+02 2.230e+02 7.400e+01 1.621e+03 4.500e+02\n",
      " 3.200e+02 8.000e+01 5.990e+02 1.534e+03 1.563e+03 3.673e+03 3.672e+03\n",
      " 4.000e+00 8.140e+02 1.943e+03 1.000e+00 1.670e+03 9.670e+02 2.700e+01\n",
      " 1.510e+03 7.630e+02 5.510e+02 3.650e+02 8.420e+02 2.000e+00 2.090e+02\n",
      " 2.650e+02 4.550e+02 1.000e+00 1.556e+03 1.400e+01 3.124e+03 3.000e+00\n",
      " 9.800e+01 1.438e+03 1.000e+00 5.740e+02 2.550e+03 1.574e+03 6.000e+00\n",
      " 1.490e+02 8.600e+02 7.900e+01 1.080e+02 8.840e+02 1.860e+02 3.810e+02\n",
      " 1.120e+02 3.540e+02 6.090e+02 4.120e+02 1.163e+03 3.300e+01 1.000e+00\n",
      " 1.221e+03 1.367e+03 1.632e+03 2.000e+01 2.145e+03 4.760e+02 1.341e+03\n",
      " 7.250e+02 1.000e+00 2.826e+03 6.460e+02 1.000e+00 5.400e+02 1.600e+02\n",
      " 2.470e+02 1.000e+00 5.370e+02 1.133e+03 9.510e+02 7.900e+01 1.911e+03\n",
      " 1.940e+02 2.000e+00 1.000e+00 3.060e+02 3.300e+02 3.767e+03 2.360e+02\n",
      " 1.388e+03 1.600e+02 7.060e+02 3.500e+01 4.690e+02 1.000e+00 5.650e+02\n",
      " 3.650e+02 1.880e+02 1.659e+03 4.000e+00 1.281e+03 2.770e+02 7.900e+02\n",
      " 1.000e+00 4.200e+01 3.170e+02 1.586e+03 1.331e+03 3.200e+01 2.044e+03\n",
      " 2.204e+03 2.490e+03 1.000e+00 2.517e+03 6.700e+01 1.204e+03 3.000e+00\n",
      " 1.728e+03 1.702e+03 6.990e+02 1.000e+00 1.000e+00 2.330e+02 1.380e+02\n",
      " 2.740e+02 1.000e+02 5.690e+02 3.000e+00 2.306e+03 9.610e+02 3.390e+02\n",
      " 1.800e+01 1.000e+00 4.050e+02 1.254e+03 2.000e+01 1.760e+02]\n",
      "Training set: 580\n",
      "Validation set: 5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_synthetic_config = DataConfig()\n",
    "test_synthetic_config.path = f\"{PACKAGE_PATH}/resources/synthetic/one_color/obs_15_75\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "test_synthetic_config.labels = [\"cz_3\", \"falcon_9\", \"atlas_5\",  \"h2a\", \"globalstar\"]\n",
    "test_synthetic_config.convert_to_mag = False\n",
    "\n",
    "test_synthetic_config.validation_split = 0.9\n",
    "trainer.load_data(test_synthetic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.val_set.data.shape[0] / 5\n",
    "trainer.train_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz_3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.7063610124998069\n",
      "\tAcc: 16.896551724137932\n",
      "Validation:\n",
      "\tLoss: 0.47414291971787925\n",
      "\tAcc: 18.52490421455939\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz_3  falcon_9  atlas_5  h2a  globalstar\n",
      "0        cz_3   866         6      164    8           0\n",
      "1    falcon_9   800        12      188   40           4\n",
      "2     atlas_5   911        44       89    0           0\n",
      "3         h2a   637         2      405    0           0\n",
      "4  globalstar  1017        11       16    0           0\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz_3   falcon_9    atlas_5  h2a  globalstar\n",
      "Precision  82.950192   1.149425   8.524904  0.0         0.0\n",
      "Recall     20.467974  16.000000  10.324826  0.0         0.0\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(test_synthetic_config.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ-3B with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "OUTPUT_PATH = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3\"\n",
    "\n",
    "# number of  data in training set\n",
    "N = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "# cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "# cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3_all$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt_unbalanced_cz3: 100%|██████████| 5/5 [00:00<00:00, 626.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: cz-3 7522 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_load import load_data\n",
    "from src.data.filters import filter_data\n",
    "\n",
    "data = load_data(cfg.data_config.path, cfg.data_config.labels, cfg.data_config.regexes, cfg.data_config.convert_to_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"cz-3\"\n",
    "data = data[label]\n",
    "indices = list(range(len(data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_data = data[indices[:N]]\n",
    "test_data = data[indices[N:]]\n",
    "\n",
    "np.save(f\"{OUTPUT_PATH}/test_{label}.npy\", test_data)\n",
    "np.save(f\"{OUTPUT_PATH}/{label}.npy\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with unbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt2\"\n",
    "# cfg.net_config.device = \"cpu\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "# cfg.data_config.labels = [\"cz-3\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3$\", r\"^falcon.?9$\", r\"^atlas.?5$\", r\"^h.?2a$\", r\"^globalstar$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "cfg.net_config.name = \"Unbalanced_cz3\"\n",
    "cfg.net_config.save_path = \"C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/models/unbalanced\"\n",
    "\n",
    "cfg.data_config.filter = FilterConfig()\n",
    "cfg.data_config.filter.n_bins = 30\n",
    "cfg.data_config.filter.n_gaps = 2\n",
    "cfg.data_config.filter.gap_size = 2\n",
    "cfg.data_config.filter.rms_ratio = .0\n",
    "cfg.data_config.filter.non_zero_ratio = 0.8\n",
    "\n",
    "np.load(f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3/test_data/falcon_9.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_dim 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder C:/Users/Kyselica/Desktop/kyselica/classification_of_light_curves/resources/real_mmt2: 100%|██████████| 5/5 [00:00<00:00, 156.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: atlas_5 2633 examples.\n",
      "Label: cz-3 9522 examples.\n",
      "Label: falcon_9 1953 examples.\n",
      "Label: globalstar 4152 examples.\n",
      "Label: h-2a 2187 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 16360\n",
      "Validation set: 4087\n"
     ]
    }
   ],
   "source": [
    "net = get_new_net(cfg)\n",
    "with open(f\"{PACKAGE_PATH}/output/configurations/{net.name}.json\", \"w\") as f:\n",
    "    print(cfg.to_json(), file=f)\n",
    "\n",
    "trainer = Trainer(net, sampler=False)\n",
    "cfg.data_config.validation_split = 0.2\n",
    "trainer.load_data(cfg.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_data(f\"{OUTPUT_PATH}/data_set_unbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 201/201 [01:20<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(201, 128,tensorboard_on=True, save_interval=50, print_on=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6719639  0.1218349  0.49928673 ... 0.62184766 0.73019231 0.07195767]\n",
      "[0.55602716 0.67909424 0.62140954 ... 0.01081043 0.57581549 0.61943754]\n"
     ]
    }
   ],
   "source": [
    "test_config = DataConfig()\n",
    "cfg.data_config.path = f\"{PACKAGE_PATH}/resources/real_mmt_unbalanced_cz3/test_data\"\n",
    "cfg.data_config.labels = [\"cz-3\", \"falcon_9\", \"atlas_5\",  \"h-2a\", \"globalstar\"]\n",
    "cfg.data_config.regexes = [r\"^cz.?3$\", r\"^falcon.?9$\", r\"^atlas.?5$\", r\"^h.?2a$\", r\"^globalstar$\"]\n",
    "cfg.data_config.convert_to_mag = False\n",
    "\n",
    "trainer.load_data(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.0026340790050717097\n",
      "\tAcc: 94.66992665036675\n",
      "Validation:\n",
      "\tLoss: 0.01280817414325924\n",
      "\tAcc: 84.68314166870566\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3  1705        78       40    53          28\n",
      "1    falcon_9   113       250        8     9          10\n",
      "2     atlas_5   104        16      369    28           9\n",
      "3        h-2a    31         5        7   385           9\n",
      "4  globalstar    17         7       20    34         752\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision  89.548319  64.102564  70.152091  88.100686   90.602410\n",
      "Recall     86.548223  70.224719  83.108108  75.638507   93.069307\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cz_3_data = np.load(f\"{OUTPUT_PATH}/test_cz3.npy\")\n",
    "cz3_labels = np.zeros((len(cz_3_data),)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.val_set.data = np.concatenate([trainer.val_set.data, cz_3_data])\n",
    "trainer.val_set.labels = np.concatenate([trainer.val_set.labels, cz3_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cz-3\n",
      "1 falcon_9\n",
      "2 atlas_5\n",
      "3 h-2a\n",
      "4 globalstar\n",
      "Train:\n",
      "\tLoss: 0.00033201762138303665\n",
      "\tAcc: 99.69915764139591\n",
      "Validation:\n",
      "\tLoss: 8.177975262498421\n",
      "\tAcc: 13.718370588902758\n",
      "-----------------------------------------\n",
      "\n",
      "        Label  cz-3  falcon_9  atlas_5  h-2a  globalstar\n",
      "0        cz-3   181         5       12     6        7518\n",
      "1    falcon_9     7       182        1     0           5\n",
      "2     atlas_5    13         7      230     1          12\n",
      "3        h-2a     8         5        2   203           0\n",
      "4  globalstar     0         0        0     2         413\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "                cz-3   falcon_9    atlas_5       h-2a  globalstar\n",
      "Precision   2.343952  93.333333  87.452471  93.119266   99.518072\n",
      "Recall     86.602871  91.457286  93.877551  95.754717    5.196276\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train_loader = None\n",
    "trainer.evaluate(cfg.data_config.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5c718b550bc3d753c2633a9373069f979ac103108d12860e85b5c2009111e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

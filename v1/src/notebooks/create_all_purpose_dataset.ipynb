{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import numpy as np\n",
    "from src.config import FilterConfig, Config, DataConfig, FourierDatasetConfig, PACKAGE_PATH\n",
    "from src.nn.datasets.utils import split_object_data_to_test_validation\n",
    "from src.data.data_load import load_data\n",
    "from src.data.filters import filter_data\n",
    "from src.experiments.constants import *\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    path=f\"{PACKAGE_PATH}/resources/Fall_2021_R_B_globalstar.csv\",\n",
    "    labels=[\"cz_3\", \"falcon_9\", \"atlas\",  \"h2a\", \"globalstar\"],\n",
    "    regexes=[r'CZ-3B.*', r'FALCON_9.*', r'ATLAS_[5|V]_CENTAUR_R\\|B$',  r'H-2A.*', r'GLOBALSTAR.*'],\n",
    "    convert_to_mag=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    number_of_training_examples_per_class = MAX_EXAMPLES,\n",
    "    validation_split = 0.1,\n",
    "    dataset_class=\"FourierDataset\",\n",
    "    dataset_arguments={},\n",
    "    filter=FilterConfig(\n",
    "        n_bins= 30,\n",
    "        n_gaps= 10,\n",
    "        gap_size= 5, \n",
    "        rms_ratio= 0.,\n",
    "        non_zero_ratio=0.8\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(data_config.path, data_config.labels, data_config.regexes, data_config.convert_to_mag)\n",
    "filtered_data = filter_data(data, data_config.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_test_validation(data, labels, k, split=0.1):\n",
    "    X_train, X_val = None, None\n",
    "    Y_train, Y_val = None, None\n",
    "    train_objects, val_objects = [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        obj_train, obj_val = split_object_data_to_test_validation(data, label, k, split)\n",
    "        print(f\"\\n{label:15}: {len(obj_train):5} training examples, {len(obj_val):5} validation examples\")\n",
    "        \n",
    "        if X_train is None:\n",
    "            X_train = obj_train\n",
    "            X_val = obj_val\n",
    "            Y_train = np.array([i]*len(obj_train))\n",
    "            Y_val = np.array([i]*len(obj_val))\n",
    "            train_objects.append((obj_train, i))\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, obj_train))\n",
    "            X_val = np.concatenate((X_val, obj_val))\n",
    "            Y_train = np.concatenate((Y_train, np.array([i]*len(obj_train))))\n",
    "            Y_val = np.concatenate((Y_val, np.array([i]*len(obj_val))))\n",
    "            val_objects.append((obj_val, i))\n",
    "\n",
    "    id_train = np.random.permutation(len(X_train))\n",
    "    id_val = np.random.permutation(len(X_val))\n",
    "\n",
    "    X_train, Y_train = X_train[id_train], Y_train[id_train]\n",
    "    X_val, Y_val = X_val[id_val], Y_val[id_val]\n",
    "\n",
    "    return (X_train, Y_train), (X_val, Y_val), train_objects, val_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
